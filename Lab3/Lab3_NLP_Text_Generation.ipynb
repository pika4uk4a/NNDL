{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EaXwg5M93cp"
      },
      "source": [
        "# Генерация текста на основе \"Гарри Поттер и методы рационального мышления\"\n",
        "\n",
        "## Описание проекта\n",
        "\n",
        "Данный проект реализует различные подходы к **генерации текста** с использованием современных методов обработки естественного языка. В качестве обучающих данных используется фанфик \"Гарри Поттер и методы рационального мышления\" - произведение, сочетающее магический мир с научным подходом к мышлению.\n",
        "\n",
        "### Основные задачи:\n",
        "- **Сбор и предобработка данных**: Извлечение текста с веб-сайта и очистка\n",
        "- **Различные типы токенизации**: Посимвольная, пословная, BPE\n",
        "- **Архитектуры нейронных сетей**: RNN, LSTM, Bidirectional LSTM, Transformer\n",
        "- **Генерация текста**: Создание новых текстов в стиле оригинала\n",
        "\n",
        "### Изучаемые модели:\n",
        "1. **Simple RNN** - базовая рекуррентная сеть\n",
        "2. **LSTM** - долгосрочная память\n",
        "3. **Bidirectional LSTM** - двунаправленная обработка\n",
        "4. **GPT-style Transformer** - архитектура внимания\n",
        "\n",
        "### Начнем с загрузки и предобработки данных:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7Fespwq93cq"
      },
      "source": [
        "## Сбор данных с веб-сайта\n",
        "\n",
        "### Загрузка текста из интернета\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6dKAr_w93cq",
        "outputId": "4b244662-7b55-4ffa-a361-1337e6b1c05b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаем загрузку текста из интернета...\n",
            "Источник: https://hpmor.ru/book/1/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Загрузка глав: 100%|██████████| 10/10 [00:13<00:00,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка завершена! Текст сохранен в файл: harry.txt\n",
            "Общий размер текста: 202277 символов\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Импорт необходимых библиотек для веб-скрапинга\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# Базовый URL для загрузки глав\n",
        "base_url = \"https://hpmor.ru/book/1/\"\n",
        "all_text = \"\"\n",
        "\n",
        "print(\"Начинаем загрузку текста из интернета...\")\n",
        "print(\"Источник: https://hpmor.ru/book/1/\")\n",
        "\n",
        "# Загружаем первые 10 глав для демонстрации\n",
        "for chapter in tqdm(range(1, 11), desc=\"Загрузка глав\"):\n",
        "    url = f\"{base_url}{chapter}/\"\n",
        "    try:\n",
        "        # Отправляем GET-запрос\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Проверяем успешность запроса\n",
        "\n",
        "        # Парсим HTML-содержимое\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "        paragraphs = soup.find_all(\"p\")\n",
        "\n",
        "        # Ищем индекс абзаца со звездочками (разделитель между метаданными и текстом)\n",
        "        start_index = next(\n",
        "            (i for i, p in enumerate(paragraphs) if p.get_text(strip=True) == \"* * *\"),\n",
        "            None\n",
        "        )\n",
        "\n",
        "        if start_index is None:\n",
        "            print(f\"Глава {chapter}: звездочки не найдены, пропускаем\")\n",
        "            continue\n",
        "\n",
        "        # Берем только абзацы после звездочек и исключаем теги <em>\n",
        "        filtered_paragraphs = [\n",
        "            p.get_text(strip=True) for p in paragraphs[start_index + 1:]\n",
        "            if not p.find(\"em\")  # Исключаем курсивные примечания\n",
        "        ]\n",
        "\n",
        "        chapter_text = \"\\n\".join(filtered_paragraphs)\n",
        "\n",
        "        # Добавляем заголовок главы и текст\n",
        "        all_text += f\"\\n\\n=== Глава {chapter} ===\\n\\n\"\n",
        "        all_text += chapter_text\n",
        "\n",
        "        # Вежливая задержка между запросами\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Глава {chapter}: ошибка — {e}\")\n",
        "\n",
        "# Сохраняем результат в файл\n",
        "with open(\"harry.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(all_text)\n",
        "\n",
        "print(\"Загрузка завершена! Текст сохранен в файл: harry.txt\")\n",
        "print(f\"Общий размер текста: {len(all_text)} символов\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a7Xpp1_93cq"
      },
      "source": [
        "## Предобработка текста\n",
        "\n",
        "### Функции очистки и нормализации\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBXSdQg_93cq",
        "outputId": "1ce63f47-4a6f-43c1-a790-4b8c7bfbc0c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Функции предобработки текста определены:\n",
            "- remove_dialog_dashes(): удаление тире из диалогов\n",
            "- keep_only_russian(): нормализация русского текста\n"
          ]
        }
      ],
      "source": [
        "# Импорт библиотек для обработки текста\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def remove_dialog_dashes(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Удаляет тире в начале строк (реплики диалога)\n",
        "\n",
        "    Args:\n",
        "        text (str): Исходный текст\n",
        "\n",
        "    Returns:\n",
        "        str: Текст без тире в начале строк\n",
        "    \"\"\"\n",
        "    # Удаляем тире, дефисы и длинные тире в начале строк\n",
        "    return re.sub(r\"(?m)^[\\s]*[–—-]\\s*\", \"\", text)\n",
        "\n",
        "def keep_only_russian(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Оставляет только русские буквы и базовые знаки препинания\n",
        "\n",
        "    Args:\n",
        "        text (str): Исходный текст\n",
        "\n",
        "    Returns:\n",
        "        str: Очищенный текст в нижнем регистре\n",
        "    \"\"\"\n",
        "    # Приводим к нижнему регистру\n",
        "    text = text.lower()\n",
        "\n",
        "    # Оставляем только русские буквы, пробелы и основные знаки препинания\n",
        "    text = re.sub(r\"[^а-яё .,!?;\\n]\", \" \", text)\n",
        "\n",
        "    # Убираем лишние пробелы\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "print(\"Функции предобработки текста определены:\")\n",
        "print(\"- remove_dialog_dashes(): удаление тире из диалогов\")\n",
        "print(\"- keep_only_russian(): нормализация русского текста\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRK5uRqr93cr",
        "outputId": "8a503d20-f904-433b-e094-5c8ff556cd8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загружен текст размером: 202277 символов\n",
            "Обработано глав: 10\n",
            "\n",
            "Примеры обработанных глав:\n",
            "   chapter                                               text\n",
            "0        1  все стены до последнего дюйма заняты книжными ...\n",
            "1        2  давайте проясним ситуацию, сказал гарри, папа,...\n",
            "2        3  господи боже! воскликнул бармен, уставившись н...\n",
            "3        4  груды галлеонов. стройные ряды серебряных сикл...\n",
            "4        5  скрытная лавка была маленьким причудливым неко...\n",
            "\n",
            "Общий размер очищенного текста: 197645 символов\n"
          ]
        }
      ],
      "source": [
        "# Загружаем сохраненный текст\n",
        "with open(\"harry.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    all_text = f.read()\n",
        "\n",
        "print(f\"Загружен текст размером: {len(all_text)} символов\")\n",
        "\n",
        "# Разделяем главы по заголовкам\n",
        "chapters_raw = re.split(r\"\\n+=+ Глава (\\d+) =+\\n+\", all_text)\n",
        "\n",
        "chapters = []\n",
        "for i in range(1, len(chapters_raw), 2):\n",
        "    chapter_number = int(chapters_raw[i])\n",
        "    chapter_text = chapters_raw[i + 1].strip()\n",
        "\n",
        "    # Применяем функции очистки\n",
        "    chapter_text = remove_dialog_dashes(chapter_text)\n",
        "    chapter_text = keep_only_russian(chapter_text)\n",
        "\n",
        "    chapters.append({\"chapter\": chapter_number, \"text\": chapter_text})\n",
        "\n",
        "# Создаем DataFrame для удобной работы с данными\n",
        "df = pd.DataFrame(chapters)\n",
        "df = df.sort_values(\"chapter\").reset_index(drop=True)\n",
        "\n",
        "print(f\"Обработано глав: {len(df)}\")\n",
        "print(\"\\nПримеры обработанных глав:\")\n",
        "print(df.head())\n",
        "\n",
        "# Объединяем весь очищенный текст\n",
        "full_cleaned_text = \" \".join(df[\"text\"].astype(str).tolist())\n",
        "print(f\"\\nОбщий размер очищенного текста: {len(full_cleaned_text)} символов\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw22S1TQ93cr"
      },
      "source": [
        "# Часть 1: Simple RNN\n",
        "\n",
        "## Посимвольная токенизация\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "ST91guLW93cr",
        "outputId": "4ac1cf16-ca03-4c14-ab69-966306c3584e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Настраиваем Simple RNN для посимвольной генерации текста...\n",
            "Размер словаря символов: 39\n",
            "Первые 20 символов: [' ', '!', ',', '.', ';', '?', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н']\n",
            "Создаем обучающие последовательности...\n",
            "Создано обучающих последовательностей: 65869\n",
            "Размер входных данных: (65869, 40, 39)\n",
            "Размер целевых данных: (65869, 39)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Архитектура модели:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m21,504\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)             │         \u001b[38;5;34m5,031\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,504</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,031</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,535\u001b[0m (103.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,535</span> (103.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,535\u001b[0m (103.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,535</span> (103.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель скомпилирована и готова к обучению!\n"
          ]
        }
      ],
      "source": [
        "# Импорт библиотек для глубокого обучения\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "\n",
        "print(\"Настраиваем Simple RNN для посимвольной генерации текста...\")\n",
        "\n",
        "# 1. Подготовка алфавита\n",
        "chars = sorted(set(full_cleaned_text))\n",
        "char2idx = {c: i for i, c in enumerate(chars)}\n",
        "idx2char = {i: c for c, i in char2idx.items()}\n",
        "vocab_size = len(chars)\n",
        "\n",
        "print(f\"Размер словаря символов: {vocab_size}\")\n",
        "print(f\"Первые 20 символов: {chars[:20]}\")\n",
        "\n",
        "# 2. Создание обучающих данных\n",
        "seq_length = 40  # Длина входной последовательности\n",
        "step = 3         # Шаг скользящего окна\n",
        "input_seqs = []\n",
        "target_chars = []\n",
        "\n",
        "print(\"Создаем обучающие последовательности...\")\n",
        "\n",
        "for i in range(0, len(full_cleaned_text) - seq_length, step):\n",
        "    input_seq = full_cleaned_text[i:i + seq_length]\n",
        "    target_char = full_cleaned_text[i + seq_length]\n",
        "    input_seqs.append([char2idx[c] for c in input_seq])\n",
        "    target_chars.append(char2idx[target_char])\n",
        "\n",
        "print(f\"Создано обучающих последовательностей: {len(input_seqs)}\")\n",
        "\n",
        "# 3. One-hot encoding\n",
        "X = tf.keras.utils.to_categorical(input_seqs, num_classes=vocab_size)\n",
        "y = tf.keras.utils.to_categorical(target_chars, num_classes=vocab_size)\n",
        "\n",
        "print(f\"Размер входных данных: {X.shape}\")\n",
        "print(f\"Размер целевых данных: {y.shape}\")\n",
        "\n",
        "# 4. Создание модели Simple RNN\n",
        "model = Sequential([\n",
        "    SimpleRNN(128, input_shape=(seq_length, vocab_size)),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "print(\"Архитектура модели:\")\n",
        "model.summary()\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "print(\"Модель скомпилирована и готова к обучению!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSLl0Wf793cr",
        "outputId": "22998614-91e0-4036-c844-447362911978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаем обучение Simple RNN...\n",
            "Это может занять некоторое время...\n",
            "Epoch 1/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - loss: 3.0089\n",
            "Epoch 2/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.4733\n",
            "Epoch 3/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 2.3618\n",
            "Epoch 4/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 2.2876\n",
            "Epoch 5/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.2365\n",
            "Epoch 6/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.2004\n",
            "Epoch 7/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.1642\n",
            "Epoch 8/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 2.1329\n",
            "Epoch 9/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.0986\n",
            "Epoch 10/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.0695\n",
            "Epoch 11/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.0457\n",
            "Epoch 12/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.0183\n",
            "Epoch 13/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.9927\n",
            "Epoch 14/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.9733\n",
            "Epoch 15/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.9445\n",
            "Epoch 16/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.9163\n",
            "Epoch 17/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.8946\n",
            "Epoch 18/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.8760\n",
            "Epoch 19/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.8580\n",
            "Epoch 20/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.8397\n",
            "Epoch 21/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.8335\n",
            "Epoch 22/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.8037\n",
            "Epoch 23/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.8011\n",
            "Epoch 24/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.7797\n",
            "Epoch 25/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.7821\n",
            "Epoch 26/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.7603\n",
            "Epoch 27/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.7500\n",
            "Epoch 28/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.7338\n",
            "Epoch 29/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.7331\n",
            "Epoch 30/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.7113\n",
            "Epoch 31/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.7138\n",
            "Epoch 32/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.6934\n",
            "Epoch 33/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.6953\n",
            "Epoch 34/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.6818\n",
            "Epoch 35/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.6759\n",
            "Epoch 36/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.6655\n",
            "Epoch 37/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.6585\n",
            "Epoch 38/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.6434\n",
            "Epoch 39/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.6264\n",
            "Epoch 40/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.6313\n",
            "Epoch 41/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.6231\n",
            "Epoch 42/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.6234\n",
            "Epoch 43/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.6144\n",
            "Epoch 44/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.6103\n",
            "Epoch 45/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5919\n",
            "Epoch 46/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5926\n",
            "Epoch 47/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5876\n",
            "Epoch 48/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5874\n",
            "Epoch 49/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5779\n",
            "Epoch 50/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5796\n",
            "Epoch 51/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5709\n",
            "Epoch 52/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5708\n",
            "Epoch 53/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5625\n",
            "Epoch 54/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5514\n",
            "Epoch 55/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5439\n",
            "Epoch 56/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5457\n",
            "Epoch 57/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.5418\n",
            "Epoch 58/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5410\n",
            "Epoch 59/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5427\n",
            "Epoch 60/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5274\n",
            "Epoch 61/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5198\n",
            "Epoch 62/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5335\n",
            "Epoch 63/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5331\n",
            "Epoch 64/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5243\n",
            "Epoch 65/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5179\n",
            "Epoch 66/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5035\n",
            "Epoch 67/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5131\n",
            "Epoch 68/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5065\n",
            "Epoch 69/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5048\n",
            "Epoch 70/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4906\n",
            "Epoch 71/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4946\n",
            "Epoch 72/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4897\n",
            "Epoch 73/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4871\n",
            "Epoch 74/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5007\n",
            "Epoch 75/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4957\n",
            "Epoch 76/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4863\n",
            "Epoch 77/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4946\n",
            "Epoch 78/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4898\n",
            "Epoch 79/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4739\n",
            "Epoch 80/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4781\n",
            "Epoch 81/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4871\n",
            "Epoch 82/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4710\n",
            "Epoch 83/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4793\n",
            "Epoch 84/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4828\n",
            "Epoch 85/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4760\n",
            "Epoch 86/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4786\n",
            "Epoch 87/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4782\n",
            "Epoch 88/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4650\n",
            "Epoch 89/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4646\n",
            "Epoch 90/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4769\n",
            "Epoch 91/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4674\n",
            "Epoch 92/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4588\n",
            "Epoch 93/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4565\n",
            "Epoch 94/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4570\n",
            "Epoch 95/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4631\n",
            "Epoch 96/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4599\n",
            "Epoch 97/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4512\n",
            "Epoch 98/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4563\n",
            "Epoch 99/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4407\n",
            "Epoch 100/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4514\n",
            "Epoch 101/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4528\n",
            "Epoch 102/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4476\n",
            "Epoch 103/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4476\n",
            "Epoch 104/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4506\n",
            "Epoch 105/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4480\n",
            "Epoch 106/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4372\n",
            "Epoch 107/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4500\n",
            "Epoch 108/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4411\n",
            "Epoch 109/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4504\n",
            "Epoch 110/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4366\n",
            "Epoch 111/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4520\n",
            "Epoch 112/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4390\n",
            "Epoch 113/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4369\n",
            "Epoch 114/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.4398\n",
            "Epoch 115/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4361\n",
            "Epoch 116/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4435\n",
            "Epoch 117/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4346\n",
            "Epoch 118/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4465\n",
            "Epoch 119/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4322\n",
            "Epoch 120/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4362\n",
            "Epoch 121/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4420\n",
            "Epoch 122/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4411\n",
            "Epoch 123/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4262\n",
            "Epoch 124/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4313\n",
            "Epoch 125/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4398\n",
            "Epoch 126/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4268\n",
            "Epoch 127/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4419\n",
            "Epoch 128/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4324\n",
            "Epoch 129/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4303\n",
            "Epoch 130/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4335\n",
            "Epoch 131/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4284\n",
            "Epoch 132/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4290\n",
            "Epoch 133/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4358\n",
            "Epoch 134/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4359\n",
            "Epoch 135/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4276\n",
            "Epoch 136/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4355\n",
            "Epoch 137/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4262\n",
            "Epoch 138/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4356\n",
            "Epoch 139/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4317\n",
            "Epoch 140/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4281\n",
            "Epoch 141/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4227\n",
            "Epoch 142/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4187\n",
            "Epoch 143/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4178\n",
            "Epoch 144/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4116\n",
            "Epoch 145/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4257\n",
            "Epoch 146/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4261\n",
            "Epoch 147/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4248\n",
            "Epoch 148/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4187\n",
            "Epoch 149/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4097\n",
            "Epoch 150/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4120\n",
            "Epoch 151/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4293\n",
            "Epoch 152/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4167\n",
            "Epoch 153/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4243\n",
            "Epoch 154/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4186\n",
            "Epoch 155/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4227\n",
            "Epoch 156/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4213\n",
            "Epoch 157/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4239\n",
            "Epoch 158/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4135\n",
            "Epoch 159/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4176\n",
            "Epoch 160/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.4189\n",
            "Epoch 161/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4053\n",
            "Epoch 162/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4161\n",
            "Epoch 163/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4186\n",
            "Epoch 164/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4220\n",
            "Epoch 165/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4106\n",
            "Epoch 166/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4101\n",
            "Epoch 167/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4152\n",
            "Epoch 168/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4102\n",
            "Epoch 169/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4156\n",
            "Epoch 170/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4151\n",
            "Epoch 171/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4123\n",
            "Epoch 172/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4105\n",
            "Epoch 173/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4109\n",
            "Epoch 174/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4082\n",
            "Epoch 175/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3988\n",
            "Epoch 176/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4114\n",
            "Epoch 177/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4137\n",
            "Epoch 178/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4139\n",
            "Epoch 179/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4125\n",
            "Epoch 180/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4114\n",
            "Epoch 181/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4033\n",
            "Epoch 182/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4077\n",
            "Epoch 183/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4051\n",
            "Epoch 184/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3970\n",
            "Epoch 185/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4093\n",
            "Epoch 186/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4195\n",
            "Epoch 187/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4179\n",
            "Epoch 188/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4058\n",
            "Epoch 189/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4189\n",
            "Epoch 190/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4020\n",
            "Epoch 191/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4106\n",
            "Epoch 192/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.4077\n",
            "Epoch 193/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4092\n",
            "Epoch 194/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4061\n",
            "Epoch 195/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4115\n",
            "Epoch 196/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4054\n",
            "Epoch 197/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3978\n",
            "Epoch 198/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4011\n",
            "Epoch 199/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4042\n",
            "Epoch 200/200\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4029\n",
            "Обучение завершено!\n"
          ]
        }
      ],
      "source": [
        "# Обучение модели Simple RNN\n",
        "print(\"Начинаем обучение Simple RNN...\")\n",
        "print(\"Это может занять некоторое время...\")\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(X, y, batch_size=128, epochs=200)\n",
        "\n",
        "print(\"Обучение завершено!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeOmC5zE93cr",
        "outputId": "f0f03d0b-9243-4680-cc8d-493e7c1e6dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Генерируем текст на основе слова 'язык':\n",
            "языкая песпетенное падирмания овретевелшей честв. котово мести. гарри она дрого маназна нагка, которые резульнутидально, порудул дразое! пресмот, по пропятанее, истоваю был геру, он пытахотицы это на мести. арадом потождан, котерсиреттилась, когда сливатьсте стале вашусть задаматак, наменденто. амаю сто\n",
            "\n",
            "Генерируем текст на основе слова 'зелье':\n",
            "зельену, и они не заметиленный деть гонагичествое правиль я подаждай. я течее делсю, было не мый открыла оничиное которые мое что вы семься садарования, которыя наждимате моно булечтоб? я стелу подертув так мо сейчашиемстной наговорде фасфакцифинка оморшаю. роначасть если пробульствая термить помождывова\n"
          ]
        }
      ],
      "source": [
        "def generate_text(seed_text, gen_length=300):\n",
        "    \"\"\"\n",
        "    Функция для генерации текста с помощью обученной модели\n",
        "\n",
        "    Args:\n",
        "        seed_text (str): Начальный текст для генерации\n",
        "        gen_length (int): Длина генерируемого текста\n",
        "\n",
        "    Returns:\n",
        "        str: Сгенерированный текст\n",
        "    \"\"\"\n",
        "    generated = seed_text\n",
        "\n",
        "    for _ in range(gen_length):\n",
        "        # Подготавливаем входную последовательность\n",
        "        input_seq = [char2idx.get(c, 0) for c in generated[-seq_length:]]\n",
        "        input_seq = tf.keras.utils.to_categorical(input_seq, num_classes=vocab_size)\n",
        "        input_seq = np.expand_dims(input_seq, axis=0)  # Добавляем размерность батча\n",
        "\n",
        "        # Получаем предсказание следующего символа\n",
        "        prediction = model.predict(input_seq, verbose=0)[0]\n",
        "\n",
        "        # Выбираем следующий символ на основе вероятностей\n",
        "        next_index = np.random.choice(range(vocab_size), p=prediction)\n",
        "        next_char = idx2char[next_index]\n",
        "\n",
        "        generated += next_char\n",
        "\n",
        "    return generated\n",
        "\n",
        "# Тестируем генерацию текста\n",
        "print(\"Генерируем текст на основе слова 'язык':\")\n",
        "generated_text1 = generate_text(\"язык\")\n",
        "print(generated_text1)\n",
        "\n",
        "print(\"\\nГенерируем текст на основе слова 'зелье':\")\n",
        "generated_text2 = generate_text(\"зелье\")\n",
        "print(generated_text2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-rD_HFo93cr"
      },
      "source": [
        "## Пословная токенизация\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "y70vUxnb93cr",
        "outputId": "9b343a05-308a-43b3-a79b-0617c28e1e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Настраиваем Simple RNN для пословной генерации...\n",
            "Всего уникальных слов: 8179\n",
            "Первые 10 слов в словаре: ['и', 'в', 'не', 'что', 'гарри', 'я', 'на', 'с', 'но', 'он']\n",
            "Количество обучающих последовательностей: 30340\n",
            "Размер входных данных: (30340, 7)\n",
            "Размер целевых данных: (30340, 8179)\n",
            "Архитектура модели для слов:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Настройка Simple RNN для пословной генерации\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "print(\"Настраиваем Simple RNN для пословной генерации...\")\n",
        "\n",
        "# 1. Подготовка: токенизация текста на слова\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([full_cleaned_text])\n",
        "\n",
        "word_index = tokenizer.word_index          # Слово → индекс\n",
        "index_word = {v: k for k, v in word_index.items()}  # Индекс → слово\n",
        "total_words = len(word_index) + 1          # Добавляем 1 для padding\n",
        "\n",
        "print(f\"Всего уникальных слов: {total_words}\")\n",
        "print(f\"Первые 10 слов в словаре: {list(word_index.keys())[:10]}\")\n",
        "\n",
        "# 2. Создание обучающих последовательностей (n-граммы)\n",
        "input_sequences = []\n",
        "words = full_cleaned_text.split()\n",
        "\n",
        "# Скользящее окно для генерации n-грамм\n",
        "window_size = 5\n",
        "for i in range(1, len(words)):\n",
        "    seq = words[max(0, i - window_size):i + 1]\n",
        "    encoded = tokenizer.texts_to_sequences([\" \".join(seq)])[0]\n",
        "    if len(encoded) >= 2:\n",
        "        input_sequences.append(encoded)\n",
        "\n",
        "print(f\"Количество обучающих последовательностей: {len(input_sequences)}\")\n",
        "\n",
        "# 3. Подготовка X и y\n",
        "max_seq_len = max(len(seq) for seq in input_sequences)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_len)\n",
        "\n",
        "X_words = input_sequences[:, :-1]  # все слова, кроме последнего\n",
        "y_words = tf.keras.utils.to_categorical(input_sequences[:, -1], num_classes=total_words)\n",
        "\n",
        "print(f\"Размер входных данных: {X_words.shape}\")\n",
        "print(f\"Размер целевых данных: {y_words.shape}\")\n",
        "\n",
        "# 4. Построение модели Simple RNN для слов\n",
        "model_word = Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=total_words, output_dim=64, input_length=X_words.shape[1]),\n",
        "    SimpleRNN(128),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "model_word.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(\"Архитектура модели для слов:\")\n",
        "model_word.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fi8tCW893cr"
      },
      "source": [
        "# Часть 2: LSTM (Long Short-Term Memory)\n",
        "\n",
        "## Однонаправленная LSTM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tpv0CJx93cr"
      },
      "source": [
        "### Посимвольная токенизация с LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "VFCloqYl93cr",
        "outputId": "32542f56-f827-45d7-fd53-361a9eae9765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Настраиваем LSTM для посимвольной генерации...\n",
            "Размер словаря символов: 39\n",
            "Размер обучающих данных: (65869, 40, 39)\n",
            "Размер целевых данных: (65869, 39)\n",
            "Архитектура однослойной LSTM:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m86,016\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)             │         \u001b[38;5;34m5,031\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,016</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,031</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91,047\u001b[0m (355.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,047</span> (355.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91,047\u001b[0m (355.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,047</span> (355.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Импорт библиотек для LSTM\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "print(\"Настраиваем LSTM для посимвольной генерации...\")\n",
        "\n",
        "# Подготовка данных (аналогично Simple RNN)\n",
        "chars = sorted(set(full_cleaned_text))\n",
        "char2idx = {c: i for i, c in enumerate(chars)}\n",
        "idx2char = {i: c for c, i in char2idx.items()}\n",
        "vocab_size = len(chars)\n",
        "\n",
        "print(f\"Размер словаря символов: {vocab_size}\")\n",
        "\n",
        "# Создание последовательностей\n",
        "seq_length = 40\n",
        "step = 3\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(full_cleaned_text) - seq_length, step):\n",
        "    seq = full_cleaned_text[i:i+seq_length]\n",
        "    target = full_cleaned_text[i+seq_length]\n",
        "    sequences.append([char2idx[c] for c in seq])\n",
        "    next_chars.append(char2idx[target])\n",
        "\n",
        "# Преобразование в one-hot encoding\n",
        "X = to_categorical(sequences, num_classes=vocab_size)\n",
        "y = to_categorical(next_chars, num_classes=vocab_size)\n",
        "\n",
        "print(f\"Размер обучающих данных: {X.shape}\")\n",
        "print(f\"Размер целевых данных: {y.shape}\")\n",
        "\n",
        "# Создание модели LSTM\n",
        "model_lstm_1 = Sequential([\n",
        "    LSTM(128, input_shape=(seq_length, vocab_size)),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model_lstm_1.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "print(\"Архитектура однослойной LSTM:\")\n",
        "model_lstm_1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k9mCT7993cr",
        "outputId": "dfb12c01-64db-4d66-9829-4917d0751037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаем обучение однослойной LSTM...\n",
            "Epoch 1/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 3.0802\n",
            "Epoch 2/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.5404\n",
            "Epoch 3/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 2.4001\n",
            "Epoch 4/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.3208\n",
            "Epoch 5/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.2495\n",
            "Epoch 6/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.1821\n",
            "Epoch 7/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 2.1276\n",
            "Epoch 8/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.0768\n",
            "Epoch 9/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.0308\n",
            "Epoch 10/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.9885\n",
            "Epoch 11/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.9450\n",
            "Epoch 12/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.9141\n",
            "Epoch 13/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.8659\n",
            "Epoch 14/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.8337\n",
            "Epoch 15/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.7898\n",
            "Epoch 16/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.7605\n",
            "Epoch 17/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.7363\n",
            "Epoch 18/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.6986\n",
            "Epoch 19/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.6701\n",
            "Epoch 20/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.6411\n",
            "Epoch 21/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.6147\n",
            "Epoch 22/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5916\n",
            "Epoch 23/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5727\n",
            "Epoch 24/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.5360\n",
            "Epoch 25/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.5110\n",
            "Epoch 26/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4737\n",
            "Epoch 27/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4594\n",
            "Epoch 28/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.4226\n",
            "Epoch 29/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4137\n",
            "Epoch 30/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.3754\n",
            "Epoch 31/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.3591\n",
            "Epoch 32/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.3348\n",
            "Epoch 33/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.3133\n",
            "Epoch 34/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.2750\n",
            "Epoch 35/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.2625\n",
            "Epoch 36/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.2495\n",
            "Epoch 37/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.2184\n",
            "Epoch 38/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.1988\n",
            "Epoch 39/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.1763\n",
            "Epoch 40/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.1516\n",
            "Epoch 41/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.1385\n",
            "Epoch 42/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.1225\n",
            "Epoch 43/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.0925\n",
            "Epoch 44/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.0718\n",
            "Epoch 45/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.0592\n",
            "Epoch 46/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.0490\n",
            "Epoch 47/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.0230\n",
            "Epoch 48/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.0030\n",
            "Epoch 49/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.9958\n",
            "Epoch 50/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.9770\n",
            "Обучение однослойной LSTM завершено!\n"
          ]
        }
      ],
      "source": [
        "# Обучение однослойной LSTM\n",
        "print(\"Начинаем обучение однослойной LSTM...\")\n",
        "\n",
        "model_lstm_1.fit(X, y, batch_size=128, epochs=50)\n",
        "\n",
        "print(\"Обучение однослойной LSTM завершено!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ci_ONAd93cr",
        "outputId": "56dfbea5-4b44-49f2-b9bc-2d63b11765af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Генерация текста с однослойной LSTM:\n",
            "Начальное слово: 'гермиона'\n",
            "гермиона урмух лискайком пер\n",
            "\n",
            "Генерация с другим начальным словом:\n",
            "Начальное слово: 'пожиратели'\n",
            "пожирателись мальнаго. гляна и\n"
          ]
        }
      ],
      "source": [
        "def generate_text_char_lstm(model, seed_text=\"гарри\", length=20, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Функция генерации текста с использованием LSTM\n",
        "\n",
        "    Args:\n",
        "        model: Обученная LSTM модель\n",
        "        seed_text (str): Начальный текст\n",
        "        length (int): Длина генерируемого текста\n",
        "        temperature (float): Температура для сэмплирования\n",
        "\n",
        "    Returns:\n",
        "        str: Сгенерированный текст\n",
        "    \"\"\"\n",
        "    generated = seed_text\n",
        "\n",
        "    for _ in range(length):\n",
        "        # Подготавливаем входную последовательность\n",
        "        input_seq = [char2idx.get(c, 0) for c in generated[-seq_length:]]\n",
        "        input_seq = tf.keras.utils.to_categorical(input_seq, num_classes=vocab_size)\n",
        "        input_seq = np.expand_dims(input_seq, axis=0)\n",
        "\n",
        "        # Получаем предсказания\n",
        "        preds = model.predict(input_seq, verbose=0)[0]\n",
        "        preds = np.asarray(preds).astype(\"float64\")\n",
        "\n",
        "        # Применяем температуру для контроля случайности\n",
        "        preds = np.log(preds + 1e-8) / temperature\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        # Выбираем следующий символ\n",
        "        next_idx = np.random.choice(range(vocab_size), p=preds)\n",
        "        next_char = idx2char[next_idx]\n",
        "        generated += next_char\n",
        "\n",
        "    return generated\n",
        "\n",
        "# Тестируем генерацию с однослойной LSTM\n",
        "print(\"Генерация текста с однослойной LSTM:\")\n",
        "print(\"Начальное слово: 'гермиона'\")\n",
        "generated_text = generate_text_char_lstm(model_lstm_1, \"гермиона\")\n",
        "print(generated_text)\n",
        "\n",
        "print(\"\\nГенерация с другим начальным словом:\")\n",
        "print(\"Начальное слово: 'пожиратели'\")\n",
        "generated_text2 = generate_text_char_lstm(model_lstm_1, \"пожиратели\")\n",
        "print(generated_text2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdQAODcQ93cs"
      },
      "source": [
        "### Многослойная LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HeTY2n-493cs",
        "outputId": "1679350b-15b0-4570-e151-e0cbafa00911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создаем многослойную LSTM модель...\n",
            "Архитектура многослойной LSTM:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m86,016\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)             │         \u001b[38;5;34m5,031\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,016</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,031</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m222,631\u001b[0m (869.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">222,631</span> (869.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m222,631\u001b[0m (869.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">222,631</span> (869.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаем обучение многослойной LSTM...\n",
            "Epoch 1/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 3.1325\n",
            "Epoch 2/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 2.5796\n",
            "Epoch 3/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 2.4132\n",
            "Epoch 4/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 2.3207\n",
            "Epoch 5/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 2.2576\n",
            "Epoch 6/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 2.1831\n",
            "Epoch 7/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 2.1371\n",
            "Epoch 8/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 2.1054\n",
            "Epoch 9/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 2.0593\n",
            "Epoch 10/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 2.0218\n",
            "Epoch 11/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1.9801\n",
            "Epoch 12/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.9405\n",
            "Epoch 13/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.9013\n",
            "Epoch 14/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 1.8673\n",
            "Epoch 15/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.8291\n",
            "Epoch 16/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.8014\n",
            "Epoch 17/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.7553\n",
            "Epoch 18/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.7164\n",
            "Epoch 19/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1.6812\n",
            "Epoch 20/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.6639\n",
            "Epoch 21/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.6412\n",
            "Epoch 22/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 1.8917\n",
            "Epoch 23/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 1.7900\n",
            "Epoch 24/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1.6056\n",
            "Epoch 25/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.5659\n",
            "Epoch 26/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.6960\n",
            "Epoch 27/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 1.5569\n",
            "Epoch 28/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.5338\n",
            "Epoch 29/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.4955\n",
            "Epoch 30/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.4593\n",
            "Epoch 31/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.4355\n",
            "Epoch 32/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1.4117\n",
            "Epoch 33/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.3968\n",
            "Epoch 34/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.3877\n",
            "Epoch 35/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1.3836\n",
            "Epoch 36/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.3741\n",
            "Epoch 37/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.3559\n",
            "Epoch 38/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1.3646\n",
            "Epoch 39/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.3467\n",
            "Epoch 40/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.3080\n",
            "Epoch 41/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1.2646\n",
            "Epoch 42/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.2303\n",
            "Epoch 43/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.2028\n",
            "Epoch 44/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 1.1743\n",
            "Epoch 45/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.2407\n",
            "Epoch 46/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1.2943\n",
            "Epoch 47/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.2492\n",
            "Epoch 48/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.2027\n",
            "Epoch 49/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1.1470\n",
            "Epoch 50/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.1466\n",
            "Обучение многослойной LSTM завершено!\n",
            "\n",
            "Генерация текста с многослойной LSTM:\n",
            "Начальное слово: 'драко'\n",
            "дракоямый молфону. если о\n",
            "\n",
            "Генерация с другим начальным словом:\n",
            "Начальное слово: 'поттер'\n",
            "поттереет из такую вы едиц\n"
          ]
        }
      ],
      "source": [
        "# Создание многослойной LSTM модели\n",
        "print(\"Создаем многослойную LSTM модель...\")\n",
        "\n",
        "model_lstm_multi = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(seq_length, vocab_size)),\n",
        "    LSTM(128),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model_lstm_multi.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "print(\"Архитектура многослойной LSTM:\")\n",
        "model_lstm_multi.summary()\n",
        "\n",
        "# Обучение многослойной LSTM\n",
        "print(\"Начинаем обучение многослойной LSTM...\")\n",
        "model_lstm_multi.fit(X, y, batch_size=128, epochs=50)\n",
        "\n",
        "print(\"Обучение многослойной LSTM завершено!\")\n",
        "\n",
        "# Тестируем многослойную LSTM\n",
        "print(\"\\nГенерация текста с многослойной LSTM:\")\n",
        "print(\"Начальное слово: 'драко'\")\n",
        "generated_multi = generate_text_char_lstm(model_lstm_multi, \"драко\")\n",
        "print(generated_multi)\n",
        "\n",
        "print(\"\\nГенерация с другим начальным словом:\")\n",
        "print(\"Начальное слово: 'поттер'\")\n",
        "generated_multi2 = generate_text_char_lstm(model_lstm_multi, \"поттер\")\n",
        "print(generated_multi2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2XHFpHb93cs"
      },
      "source": [
        "### Пословная токенизация с LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_TLWLtBM93cs",
        "outputId": "481c7c57-e19c-42cd-82b8-8143be70b882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Настраиваем LSTM для пословной генерации...\n",
            "Общий словарь слов: 8179\n",
            "Размер обучающих данных: (30340, 7)\n",
            "Размер целевых данных: (30340, 8179)\n",
            "Архитектура однослойной LSTM для слов:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаем обучение однослойной LSTM для слов...\n",
            "Epoch 1/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 8.2286\n",
            "Epoch 2/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 7.4128\n",
            "Epoch 3/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 7.2821\n",
            "Epoch 4/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 7.1974\n",
            "Epoch 5/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 7.1221\n",
            "Epoch 6/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 7.0313\n",
            "Epoch 7/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.8700\n",
            "Epoch 8/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 6.7069\n",
            "Epoch 9/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.5347\n",
            "Epoch 10/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 6.3587\n",
            "Epoch 11/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 6.1644\n",
            "Epoch 12/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.9806\n",
            "Epoch 13/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 5.8078\n",
            "Epoch 14/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 5.6344\n",
            "Epoch 15/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.4378\n",
            "Epoch 16/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.2687\n",
            "Epoch 17/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.1023\n",
            "Epoch 18/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.9197\n",
            "Epoch 19/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.7649\n",
            "Epoch 20/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 4.5733\n",
            "Epoch 21/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.4181\n",
            "Epoch 22/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.2409\n",
            "Epoch 23/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.0765\n",
            "Epoch 24/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.9166\n",
            "Epoch 25/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 3.7349\n",
            "Epoch 26/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.5856\n",
            "Epoch 27/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 3.4419\n",
            "Epoch 28/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 3.3120\n",
            "Epoch 29/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.1541\n",
            "Epoch 30/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.0308\n",
            "Epoch 31/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 2.9096\n",
            "Epoch 32/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.7506\n",
            "Epoch 33/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 2.6413\n",
            "Epoch 34/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 2.5344\n",
            "Epoch 35/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.3938\n",
            "Epoch 36/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 2.2959\n",
            "Epoch 37/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.1953\n",
            "Epoch 38/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.1150\n",
            "Epoch 39/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.0208\n",
            "Epoch 40/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.9302\n",
            "Epoch 41/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.8404\n",
            "Epoch 42/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.7591\n",
            "Epoch 43/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.6830\n",
            "Epoch 44/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6096\n",
            "Epoch 45/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.5376\n",
            "Epoch 46/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.4707\n",
            "Epoch 47/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.4140\n",
            "Epoch 48/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 1.3486\n",
            "Epoch 49/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.2966\n",
            "Epoch 50/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.2250\n",
            "Epoch 51/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.1793\n",
            "Epoch 52/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.1197\n",
            "Epoch 53/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.0604\n",
            "Epoch 54/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.0234\n",
            "Epoch 55/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.9801\n",
            "Epoch 56/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.9275\n",
            "Epoch 57/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.8866\n",
            "Epoch 58/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.8486\n",
            "Epoch 59/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.8140\n",
            "Epoch 60/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.7581\n",
            "Epoch 61/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.7316\n",
            "Epoch 62/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.7017\n",
            "Epoch 63/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.6710\n",
            "Epoch 64/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.6303\n",
            "Epoch 65/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.6122\n",
            "Epoch 66/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.5761\n",
            "Epoch 67/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.5526\n",
            "Epoch 68/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5245\n",
            "Epoch 69/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.5099\n",
            "Epoch 70/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.4712\n",
            "Epoch 71/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.4569\n",
            "Epoch 72/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.4416\n",
            "Epoch 73/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.4175\n",
            "Epoch 74/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.3902\n",
            "Epoch 75/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3724\n",
            "Epoch 76/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3573\n",
            "Epoch 77/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.3349\n",
            "Epoch 78/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.3291\n",
            "Epoch 79/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3037\n",
            "Epoch 80/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2833\n",
            "Epoch 81/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2699\n",
            "Epoch 82/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2533\n",
            "Epoch 83/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.2412\n",
            "Epoch 84/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2361\n",
            "Epoch 85/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2104\n",
            "Epoch 86/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2156\n",
            "Epoch 87/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1953\n",
            "Epoch 88/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1858\n",
            "Epoch 89/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1788\n",
            "Epoch 90/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1664\n",
            "Epoch 91/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1531\n",
            "Epoch 92/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1457\n",
            "Epoch 93/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1479\n",
            "Epoch 94/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1289\n",
            "Epoch 95/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1209\n",
            "Epoch 96/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1113\n",
            "Epoch 97/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1118\n",
            "Epoch 98/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1051\n",
            "Epoch 99/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0989\n",
            "Epoch 100/100\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0938\n",
            "Обучение завершено!\n"
          ]
        }
      ],
      "source": [
        "# Настройка LSTM для пословной генерации\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "print(\"Настраиваем LSTM для пословной генерации...\")\n",
        "\n",
        "# Токенизация слов\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([full_cleaned_text])\n",
        "word_index = tokenizer.word_index\n",
        "index_word = {v: k for k, v in word_index.items()}\n",
        "total_words = len(word_index) + 1\n",
        "\n",
        "print(f\"Общий словарь слов: {total_words}\")\n",
        "\n",
        "# Создание последовательностей слов\n",
        "input_sequences = []\n",
        "words = full_cleaned_text.split()\n",
        "\n",
        "for i in range(1, len(words)):\n",
        "    ngram = words[max(0, i-5):i+1]\n",
        "    encoded = tokenizer.texts_to_sequences([\" \".join(ngram)])[0]\n",
        "    if len(encoded) >= 2:\n",
        "        input_sequences.append(encoded)\n",
        "\n",
        "max_len = max(len(seq) for seq in input_sequences)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_len)\n",
        "\n",
        "X_words = input_sequences[:, :-1]\n",
        "y_words = to_categorical(input_sequences[:, -1], num_classes=total_words)\n",
        "\n",
        "print(f\"Размер обучающих данных: {X_words.shape}\")\n",
        "print(f\"Размер целевых данных: {y_words.shape}\")\n",
        "\n",
        "# Создание однослойной LSTM для слов\n",
        "model_words_1 = Sequential([\n",
        "    tf.keras.layers.Embedding(total_words, 64, input_length=X_words.shape[1]),\n",
        "    LSTM(128),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "model_words_1.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "print(\"Архитектура однослойной LSTM для слов:\")\n",
        "model_words_1.summary()\n",
        "\n",
        "# Обучение модели\n",
        "print(\"Начинаем обучение однослойной LSTM для слов...\")\n",
        "model_words_1.fit(X_words, y_words, epochs=100, batch_size=128)\n",
        "\n",
        "print(\"Обучение завершено!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1OIk6JM93cs",
        "outputId": "7516da76-3e55-4071-9ca9-baa82664dcdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Генерация текста по словам с LSTM:\n",
            "Начальная фраза: 'волшебная палочка'\n",
            "волшебная палочка я не был вспомнить может быть развернулась ахава разговаривать интересно\n",
            "\n",
            "Генерация с другой фразой:\n",
            "Начальная фраза: 'малфой'\n",
            "малфой и ни мальчик кашлянул же его запнулась на случай мой\n"
          ]
        }
      ],
      "source": [
        "def generate_text_word_lstm(model, seed_text, num_words=10, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Функция генерации текста по словам с использованием LSTM\n",
        "\n",
        "    Args:\n",
        "        model: Обученная LSTM модель\n",
        "        seed_text (str): Начальный текст\n",
        "        num_words (int): Количество слов для генерации\n",
        "        temperature (float): Температура для сэмплирования\n",
        "\n",
        "    Returns:\n",
        "        str: Сгенерированный текст\n",
        "    \"\"\"\n",
        "    for _ in range(num_words):\n",
        "        # Токенизируем текущий текст\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=X_words.shape[1])\n",
        "\n",
        "        # Получаем предсказания\n",
        "        preds = model.predict(token_list, verbose=0)[0]\n",
        "        preds = np.log(preds + 1e-8) / temperature\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        # Выбираем следующее слово\n",
        "        next_index = np.random.choice(range(total_words), p=preds)\n",
        "        next_word = index_word.get(next_index, \"\")\n",
        "        seed_text += \" \" + next_word\n",
        "\n",
        "    return seed_text\n",
        "\n",
        "# Тестируем генерацию слов\n",
        "print(\"Генерация текста по словам с LSTM:\")\n",
        "print(\"Начальная фраза: 'волшебная палочка'\")\n",
        "generated_words = generate_text_word_lstm(model_words_1, \"волшебная палочка\")\n",
        "print(generated_words)\n",
        "\n",
        "print(\"\\nГенерация с другой фразой:\")\n",
        "print(\"Начальная фраза: 'малфой'\")\n",
        "generated_words2 = generate_text_word_lstm(model_words_1, \"малфой\")\n",
        "print(generated_words2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJAO82nH93cs"
      },
      "source": [
        "## BPE (Byte Pair Encoding) токенизация\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubukcR2093cs",
        "outputId": "b9573290-b957-41e8-bd33-d70a45732b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Библиотека tokenizers уже установлена\n",
            "Настраиваем BPE токенизацию...\n",
            "BPE токенизатор обучен!\n",
            "Размер словаря BPE: 13265\n",
            "Размер обучающих данных: (36487, 40)\n",
            "Размер целевых данных: (36487, 13265)\n"
          ]
        }
      ],
      "source": [
        "# Установка библиотеки tokenizers для BPE\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
        "    print(\"Библиотека tokenizers уже установлена\")\n",
        "except ImportError:\n",
        "    print(\"Устанавливаем библиотеку tokenizers...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"tokenizers\"])\n",
        "    from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "print(\"Настраиваем BPE токенизацию...\")\n",
        "\n",
        "# Создаем и обучаем BPE токенизатор\n",
        "bpe_tokenizer = Tokenizer(models.BPE())\n",
        "trainer = trainers.BpeTrainer(special_tokens=[\"<PAD>\"])\n",
        "bpe_tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "bpe_tokenizer.train_from_iterator(full_cleaned_text.splitlines(), trainer)\n",
        "\n",
        "print(\"BPE токенизатор обучен!\")\n",
        "\n",
        "# Создание последовательностей с BPE токенизацией\n",
        "tokens = bpe_tokenizer.encode(full_cleaned_text).ids\n",
        "seq_len = 40\n",
        "X_bpe, y_bpe = [], []\n",
        "\n",
        "for i in range(seq_len, len(tokens)):\n",
        "    X_bpe.append(tokens[i-seq_len:i])\n",
        "    y_bpe.append(tokens[i])\n",
        "\n",
        "vocab_size_bpe = bpe_tokenizer.get_vocab_size()\n",
        "\n",
        "X_bpe = np.array(X_bpe)\n",
        "y_bpe = to_categorical(y_bpe, num_classes=vocab_size_bpe)\n",
        "\n",
        "print(f\"Размер словаря BPE: {vocab_size_bpe}\")\n",
        "print(f\"Размер обучающих данных: {X_bpe.shape}\")\n",
        "print(f\"Размер целевых данных: {y_bpe.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwSVNQoB93cs"
      },
      "source": [
        "### Однослойная LSTM с BPE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_HklJJ2w93cs",
        "outputId": "b9dd45e4-d99a-4cbe-a985-aeb35ecfcdc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Архитектура однослойной LSTM с BPE:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаем обучение однослойной LSTM с BPE...\n",
            "Epoch 1/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 7.8886\n",
            "Epoch 2/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 6.7055\n",
            "Epoch 3/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 6.4712\n",
            "Epoch 4/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 6.3003\n",
            "Epoch 5/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 6.1378\n",
            "Epoch 6/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 5.9955\n",
            "Epoch 7/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 5.8899\n",
            "Epoch 8/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.7438\n",
            "Epoch 9/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 5.6149\n",
            "Epoch 10/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 5.4954\n",
            "Epoch 11/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 5.3711\n",
            "Epoch 12/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 5.2643\n",
            "Epoch 13/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 5.1454\n",
            "Epoch 14/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 5.0087\n",
            "Epoch 15/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 4.9093\n",
            "Epoch 16/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.7802\n",
            "Epoch 17/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 4.6569\n",
            "Epoch 18/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 4.5816\n",
            "Epoch 19/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 4.4441\n",
            "Epoch 20/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 4.3297\n",
            "Epoch 21/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 4.2124\n",
            "Epoch 22/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 4.1000\n",
            "Epoch 23/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 3.9800\n",
            "Epoch 24/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 3.8653\n",
            "Epoch 25/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.7510\n",
            "Epoch 26/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 3.6696\n",
            "Epoch 27/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 3.5599\n",
            "Epoch 28/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 3.4384\n",
            "Epoch 29/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 3.3668\n",
            "Epoch 30/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.2440\n",
            "Epoch 31/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 3.1464\n",
            "Epoch 32/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 3.0894\n",
            "Epoch 33/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.9816\n",
            "Epoch 34/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 2.9159\n",
            "Epoch 35/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 2.8572\n",
            "Epoch 36/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 2.7558\n",
            "Epoch 37/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 2.6902\n",
            "Epoch 38/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.6391\n",
            "Epoch 39/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.5723\n",
            "Epoch 40/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.5062\n",
            "Epoch 41/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 2.4508\n",
            "Epoch 42/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.4185\n",
            "Epoch 43/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.3321\n",
            "Epoch 44/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 2.3063\n",
            "Epoch 45/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.2543\n",
            "Epoch 46/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 2.2082\n",
            "Epoch 47/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.1729\n",
            "Epoch 48/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.1257\n",
            "Epoch 49/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.0956\n",
            "Epoch 50/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.0599\n",
            "Epoch 51/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.0250\n",
            "Epoch 52/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.9730\n",
            "Epoch 53/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.9507\n",
            "Epoch 54/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.8965\n",
            "Epoch 55/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.8672\n",
            "Epoch 56/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.8228\n",
            "Epoch 57/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.7958\n",
            "Epoch 58/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 1.7735\n",
            "Epoch 59/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.7304\n",
            "Epoch 60/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 1.6996\n",
            "Epoch 61/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.6689\n",
            "Epoch 62/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.6406\n",
            "Epoch 63/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 1.6272\n",
            "Epoch 64/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.5801\n",
            "Epoch 65/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.5625\n",
            "Epoch 66/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.5299\n",
            "Epoch 67/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.5127\n",
            "Epoch 68/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.4894\n",
            "Epoch 69/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.4533\n",
            "Epoch 70/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.4463\n",
            "Epoch 71/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.4105\n",
            "Epoch 72/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.3852\n",
            "Epoch 73/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.3546\n",
            "Epoch 74/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3441\n",
            "Epoch 75/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3093\n",
            "Epoch 76/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.2918\n",
            "Epoch 77/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.2796\n",
            "Epoch 78/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 1.2411\n",
            "Epoch 79/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.2361\n",
            "Epoch 80/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2294\n",
            "Epoch 81/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.1874\n",
            "Epoch 82/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.1637\n",
            "Epoch 83/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1429\n",
            "Epoch 84/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.1324\n",
            "Epoch 85/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.1101\n",
            "Epoch 86/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.0896\n",
            "Epoch 87/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.0758\n",
            "Epoch 88/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 1.0578\n",
            "Epoch 89/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 1.0286\n",
            "Epoch 90/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 1.0258\n",
            "Epoch 91/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.9877\n",
            "Epoch 92/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.9884\n",
            "Epoch 93/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.9606\n",
            "Epoch 94/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.9373\n",
            "Epoch 95/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.9212\n",
            "Epoch 96/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.9177\n",
            "Epoch 97/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.9083\n",
            "Epoch 98/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.8797\n",
            "Epoch 99/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.8742\n",
            "Epoch 100/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.8607\n",
            "Epoch 101/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.8332\n",
            "Epoch 102/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.8135\n",
            "Epoch 103/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.8117\n",
            "Epoch 104/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.7968\n",
            "Epoch 105/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.7762\n",
            "Epoch 106/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.7594\n",
            "Epoch 107/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.7531\n",
            "Epoch 108/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.7443\n",
            "Epoch 109/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.7320\n",
            "Epoch 110/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.7135\n",
            "Epoch 111/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.6958\n",
            "Epoch 112/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.6817\n",
            "Epoch 113/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.6707\n",
            "Epoch 114/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.6640\n",
            "Epoch 115/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.6470\n",
            "Epoch 116/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.6333\n",
            "Epoch 117/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.6392\n",
            "Epoch 118/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.6236\n",
            "Epoch 119/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.6107\n",
            "Epoch 120/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.5944\n",
            "Epoch 121/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.5746\n",
            "Epoch 122/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.5757\n",
            "Epoch 123/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.5639\n",
            "Epoch 124/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.5620\n",
            "Epoch 125/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.5388\n",
            "Epoch 126/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.5303\n",
            "Epoch 127/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.5117\n",
            "Epoch 128/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.5078\n",
            "Epoch 129/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.4906\n",
            "Epoch 130/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4892\n",
            "Epoch 131/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.4758\n",
            "Epoch 132/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.4742\n",
            "Epoch 133/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.4582\n",
            "Epoch 134/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4540\n",
            "Epoch 135/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.4492\n",
            "Epoch 136/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.4423\n",
            "Epoch 137/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.4416\n",
            "Epoch 138/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.4188\n",
            "Epoch 139/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.4097\n",
            "Epoch 140/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.3991\n",
            "Epoch 141/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3918\n",
            "Epoch 142/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.3827\n",
            "Epoch 143/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.3777\n",
            "Epoch 144/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.3641\n",
            "Epoch 145/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.3690\n",
            "Epoch 146/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3635\n",
            "Epoch 147/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.3505\n",
            "Epoch 148/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.3397\n",
            "Epoch 149/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3275\n",
            "Epoch 150/150\n",
            "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.3317\n",
            "Обучение завершено!\n",
            "Генерация текста с BPE токенизацией:\n",
            "Начальная фраза: 'заклинание против'\n",
            "заклинание против тёмного лорда , успокоил гарри . в магазине смертельное проклятие . на этом всё и кончилось . это проклятие формируется из чистой ненависти и бьёт прямо в душу , отделяя её сундук . к курицы ?.. ах ты задумался , сколько даже не знал со встроенной системой парня , встала\n",
            "\n",
            "Генерация с другой фразой:\n",
            "Начальная фраза: 'проклятые маглы'\n",
            "прокля тые маглы , но что волшебники относились в свою помощницу , вы пожимаете им руки . в этом году он будет преподавать в магазине ингредиентов она старалась не видела , но не объясняйте , какое из них не раньше . гарри снова ! затем он ! да , сказал стоит часть за\n"
          ]
        }
      ],
      "source": [
        "# Создание однослойной LSTM модели с BPE\n",
        "model_bpe_1 = Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size_bpe, 64, input_length=seq_len),\n",
        "    LSTM(128),\n",
        "    Dense(vocab_size_bpe, activation='softmax')\n",
        "])\n",
        "\n",
        "model_bpe_1.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "print(\"Архитектура однослойной LSTM с BPE:\")\n",
        "model_bpe_1.summary()\n",
        "\n",
        "# Обучение модели\n",
        "print(\"Начинаем обучение однослойной LSTM с BPE...\")\n",
        "model_bpe_1.fit(X_bpe, y_bpe, epochs=150, batch_size=128)\n",
        "\n",
        "print(\"Обучение завершено!\")\n",
        "\n",
        "# Функция генерации с BPE\n",
        "def generate_text_bpe_lstm(model, tokenizer_bpe, seed_text, gen_tokens=50, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Функция генерации текста с использованием BPE токенизации\n",
        "\n",
        "    Args:\n",
        "        model: Обученная модель\n",
        "        tokenizer_bpe: BPE токенизатор\n",
        "        seed_text (str): Начальный текст\n",
        "        gen_tokens (int): Количество токенов для генерации\n",
        "        temperature (float): Температура сэмплирования\n",
        "\n",
        "    Returns:\n",
        "        str: Сгенерированный текст\n",
        "    \"\"\"\n",
        "    tokens = tokenizer_bpe.encode(seed_text).ids\n",
        "    generated = tokens[:]\n",
        "\n",
        "    for _ in range(gen_tokens):\n",
        "        input_seq = generated[-seq_len:]\n",
        "        input_seq = pad_sequences([input_seq], maxlen=seq_len)\n",
        "\n",
        "        preds = model.predict(input_seq, verbose=0)[0]\n",
        "        preds = np.log(preds + 1e-8) / temperature\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        next_index = np.random.choice(range(vocab_size_bpe), p=preds)\n",
        "        generated.append(next_index)\n",
        "\n",
        "    decoded = tokenizer_bpe.decode(generated)\n",
        "    return decoded\n",
        "\n",
        "# Тестируем генерацию с BPE\n",
        "print(\"Генерация текста с BPE токенизацией:\")\n",
        "print(\"Начальная фраза: 'заклинание против'\")\n",
        "generated_bpe = generate_text_bpe_lstm(model_bpe_1, bpe_tokenizer, \"заклинание против\")\n",
        "print(generated_bpe)\n",
        "\n",
        "print(\"\\nГенерация с другой фразой:\")\n",
        "print(\"Начальная фраза: 'проклятые маглы'\")\n",
        "generated_bpe2 = generate_text_bpe_lstm(model_bpe_1, bpe_tokenizer, \"проклятые маглы\")\n",
        "print(generated_bpe2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuZOU36I93cs"
      },
      "source": [
        "# Часть 3: Двунаправленная LSTM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "httxwQGD93cs"
      },
      "source": [
        "## Посимвольная токенизация с Bidirectional LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G9dhpi7293cs",
        "outputId": "421187b0-d136-4dbe-e15c-6172d7739b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Настраиваем Bidirectional LSTM для посимвольной генерации...\n",
            "Размер обучающих данных: (65869, 40, 39)\n",
            "Размер целевых данных: (65869, 39)\n",
            "Архитектура Bidirectional LSTM:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m172,032\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)             │        \u001b[38;5;34m10,023\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">172,032</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,023</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m182,055\u001b[0m (711.15 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">182,055</span> (711.15 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m182,055\u001b[0m (711.15 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">182,055</span> (711.15 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаем обучение Bidirectional LSTM...\n",
            "Epoch 1/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 3.0902\n",
            "Epoch 2/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 2.5454\n",
            "Epoch 3/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 2.3861\n",
            "Epoch 4/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 2.2891\n",
            "Epoch 5/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 2.2190\n",
            "Epoch 6/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 2.1429\n",
            "Epoch 7/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 2.0844\n",
            "Epoch 8/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 2.0300\n",
            "Epoch 9/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 1.9666\n",
            "Epoch 10/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.9155\n",
            "Epoch 11/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 1.8755\n",
            "Epoch 12/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.8209\n",
            "Epoch 13/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.7737\n",
            "Epoch 14/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1.7284\n",
            "Epoch 15/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.6767\n",
            "Epoch 16/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.6347\n",
            "Epoch 17/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 1.5804\n",
            "Epoch 18/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.5273\n",
            "Epoch 19/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 1.4784\n",
            "Epoch 20/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 1.4397\n",
            "Epoch 21/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.4002\n",
            "Epoch 22/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1.3502\n",
            "Epoch 23/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.3006\n",
            "Epoch 24/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1.2653\n",
            "Epoch 25/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1.2096\n",
            "Epoch 26/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 1.1698\n",
            "Epoch 27/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.1191\n",
            "Epoch 28/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 1.0762\n",
            "Epoch 29/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.0364\n",
            "Epoch 30/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.9986\n",
            "Epoch 31/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.9457\n",
            "Epoch 32/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.9121\n",
            "Epoch 33/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.8738\n",
            "Epoch 34/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.8355\n",
            "Epoch 35/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.8065\n",
            "Epoch 36/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.7641\n",
            "Epoch 37/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.7316\n",
            "Epoch 38/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.7054\n",
            "Epoch 39/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.6611\n",
            "Epoch 40/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.6363\n",
            "Epoch 41/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.6173\n",
            "Epoch 42/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.5879\n",
            "Epoch 43/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.5615\n",
            "Epoch 44/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.5405\n",
            "Epoch 45/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.5087\n",
            "Epoch 46/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.4951\n",
            "Epoch 47/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.4781\n",
            "Epoch 48/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.4519\n",
            "Epoch 49/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.4389\n",
            "Epoch 50/50\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.4123\n",
            "Обучение завершено!\n",
            "Генерация текста с Bidirectional LSTM:\n",
            "Начальное слово: 'заклинание'\n",
            "заклинание магии оста. вольже. у вам давимастоврание. сейчас кти снаю \n"
          ]
        }
      ],
      "source": [
        "# Импорт библиотек для Bidirectional LSTM\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "print(\"Настраиваем Bidirectional LSTM для посимвольной генерации...\")\n",
        "\n",
        "# Подготовка данных (аналогично предыдущим моделям)\n",
        "chars = sorted(set(full_cleaned_text))\n",
        "char2idx = {c: i for i, c in enumerate(chars)}\n",
        "idx2char = {i: c for c, i in char2idx.items()}\n",
        "vocab_size = len(chars)\n",
        "\n",
        "# Создание последовательностей\n",
        "seq_length = 40\n",
        "step = 3\n",
        "input_seqs, target_chars = [], []\n",
        "\n",
        "for i in range(0, len(full_cleaned_text) - seq_length, step):\n",
        "    seq = full_cleaned_text[i:i + seq_length]\n",
        "    target = full_cleaned_text[i + seq_length]\n",
        "    input_seqs.append([char2idx[c] for c in seq])\n",
        "    target_chars.append(char2idx[target])\n",
        "\n",
        "X_char = tf.keras.utils.to_categorical(input_seqs, num_classes=vocab_size)\n",
        "y_char = tf.keras.utils.to_categorical(target_chars, num_classes=vocab_size)\n",
        "\n",
        "print(f\"Размер обучающих данных: {X_char.shape}\")\n",
        "print(f\"Размер целевых данных: {y_char.shape}\")\n",
        "\n",
        "# Создание модели Bidirectional LSTM\n",
        "model_char = Sequential([\n",
        "    Bidirectional(LSTM(128), input_shape=(seq_length, vocab_size)),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model_char.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "print(\"Архитектура Bidirectional LSTM:\")\n",
        "model_char.summary()\n",
        "\n",
        "# Обучение модели\n",
        "print(\"Начинаем обучение Bidirectional LSTM...\")\n",
        "model_char.fit(X_char, y_char, batch_size=128, epochs=50)\n",
        "\n",
        "print(\"Обучение завершено!\")\n",
        "\n",
        "# Функция генерации для Bidirectional LSTM\n",
        "def generate_char_text(model, seed_text=\"гарри\", length=20, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Функция генерации текста с Bidirectional LSTM\n",
        "\n",
        "    Args:\n",
        "        model: Обученная модель\n",
        "        seed_text (str): Начальный текст\n",
        "        length (int): Длина генерируемого текста\n",
        "        temperature (float): Температура сэмплирования\n",
        "\n",
        "    Returns:\n",
        "        str: Сгенерированный текст\n",
        "    \"\"\"\n",
        "    generated = seed_text\n",
        "\n",
        "    for _ in range(length):\n",
        "        input_seq = [char2idx.get(c, 0) for c in generated[-seq_length:]]\n",
        "        input_seq = tf.keras.utils.to_categorical(input_seq, num_classes=vocab_size)\n",
        "        input_seq = np.expand_dims(input_seq, axis=0)\n",
        "\n",
        "        preds = model.predict(input_seq, verbose=0)[0]\n",
        "        preds = np.log(preds + 1e-8) / temperature\n",
        "        preds = np.exp(preds) / np.sum(np.exp(preds))\n",
        "\n",
        "        next_idx = np.random.choice(range(vocab_size), p=preds)\n",
        "        next_char = idx2char[next_idx]\n",
        "        generated += next_char\n",
        "\n",
        "    return generated\n",
        "\n",
        "# Тестируем генерацию\n",
        "print(\"Генерация текста с Bidirectional LSTM:\")\n",
        "print(\"Начальное слово: 'заклинание'\")\n",
        "generated_char = generate_char_text(model_char, \"заклинание\", length=60)\n",
        "print(generated_char)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t1Vd7VC93ct"
      },
      "source": [
        "# Часть 4: GPT с нуля\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQZbnB9e93ct"
      },
      "source": [
        "## Символьная GPT модель\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgwgC1rf93ct",
        "outputId": "40359ae9-24a0-46e9-8055-3c7fc1561cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создаем GPT-style модель с нуля...\n",
            "Размер словаря символов: 39\n",
            "Размер входных данных: (197581, 64)\n",
            "Размер целевых данных: (197581, 39)\n",
            "Кастомные слои Transformer определены!\n"
          ]
        }
      ],
      "source": [
        "# Импорт библиотек для Transformer архитектуры\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "print(\"Создаем GPT-style модель с нуля...\")\n",
        "\n",
        "# Подготовка данных для символов\n",
        "vocab = sorted(set(full_cleaned_text))\n",
        "char2idx = {c: i for i, c in enumerate(vocab)}\n",
        "idx2char = {i: c for c, i in char2idx.items()}\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(f\"Размер словаря символов: {vocab_size}\")\n",
        "\n",
        "# Преобразование в числовой вид\n",
        "encoded = [char2idx[c] for c in full_cleaned_text]\n",
        "\n",
        "# Создание обучающих пар\n",
        "context_len = 64\n",
        "X, y = [], []\n",
        "for i in range(len(encoded) - context_len):\n",
        "    X.append(encoded[i:i + context_len])\n",
        "    y.append(encoded[i + context_len])\n",
        "\n",
        "X = np.array(X)\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "print(f\"Размер входных данных: {X.shape}\")\n",
        "print(f\"Размер целевых данных: {y.shape}\")\n",
        "\n",
        "# Определение кастомных слоев для Transformer\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "class MaskedSelfAttention(Layer):\n",
        "    \"\"\"\n",
        "    Слой маскированного self-attention для GPT архитектуры\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.proj_q = Dense(embed_dim)\n",
        "        self.proj_k = Dense(embed_dim)\n",
        "        self.proj_v = Dense(embed_dim)\n",
        "        self.out = Dense(embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        B, T, C = tf.shape(x)[0], tf.shape(x)[1], self.embed_dim\n",
        "        q = self.proj_q(x)\n",
        "        k = self.proj_k(x)\n",
        "        v = self.proj_v(x)\n",
        "\n",
        "        # Разделение на головы внимания\n",
        "        q = tf.concat(tf.split(q, self.num_heads, axis=-1), axis=0)\n",
        "        k = tf.concat(tf.split(k, self.num_heads, axis=-1), axis=0)\n",
        "        v = tf.concat(tf.split(v, self.num_heads, axis=-1), axis=0)\n",
        "\n",
        "        # Вычисление attention scores\n",
        "        att = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(tf.cast(C // self.num_heads, tf.float32))\n",
        "\n",
        "        # Маскирование будущих позиций (causal mask)\n",
        "        mask = tf.linalg.band_part(tf.ones((T, T)), -1, 0)\n",
        "        att = tf.where(mask == 0, -1e10, att)\n",
        "\n",
        "        att = tf.nn.softmax(att, axis=-1)\n",
        "        out = tf.matmul(att, v)\n",
        "        out = tf.concat(tf.split(out, self.num_heads, axis=0), axis=-1)\n",
        "        return self.out(out)\n",
        "\n",
        "class TransformerBlock(Layer):\n",
        "    \"\"\"\n",
        "    Блок Transformer с self-attention и feed-forward сетью\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim):\n",
        "        super().__init__()\n",
        "        self.att = MaskedSelfAttention(embed_dim, num_heads)\n",
        "        self.norm1 = LayerNormalization()\n",
        "        self.ff = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation='relu'),\n",
        "            Dense(embed_dim)\n",
        "        ])\n",
        "        self.norm2 = LayerNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        # Self-attention с residual connection\n",
        "        x = x + self.att(self.norm1(x))\n",
        "        # Feed-forward с residual connection\n",
        "        x = x + self.ff(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    \"\"\"\n",
        "    Позиционное кодирование для Transformer\n",
        "    \"\"\"\n",
        "    def __init__(self, max_len, embed_dim):\n",
        "        super().__init__()\n",
        "        pos = np.arange(max_len)[:, None]\n",
        "        i = np.arange(embed_dim)[None, :]\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(embed_dim))\n",
        "        angle_rads = pos * angle_rates\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "        self.pos_encoding = tf.constant(angle_rads[np.newaxis, ...], dtype=tf.float32)\n",
        "\n",
        "    def call(self, x):\n",
        "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]\n",
        "\n",
        "print(\"Кастомные слои Transformer определены!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "puDjh4r893ct",
        "outputId": "e571c67f-460c-4dc2-d15e-41be98d52628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создаем GPT модель с параметрами:\n",
            "- Размерность эмбеддинга: 128\n",
            "- Количество голов внимания: 4\n",
            "- Размерность feed-forward: 256\n",
            "- Количество слоев: 4\n",
            "Архитектура GPT модели:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m4,992\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ positional_encoding             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m132,480\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m132,480\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m132,480\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m132,480\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)             │         \u001b[38;5;34m5,031\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,992</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ positional_encoding             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,480</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,480</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,480</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,480</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,031</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m539,943\u001b[0m (2.06 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">539,943</span> (2.06 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m539,943\u001b[0m (2.06 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">539,943</span> (2.06 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаем обучение GPT модели...\n",
            "Внимание: Обучение может занять значительное время!\n",
            "Epoch 1/10\n",
            "\u001b[1m1544/1544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 24ms/step - loss: 2.9251\n",
            "Epoch 2/10\n",
            "\u001b[1m1544/1544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 2.1664\n",
            "Epoch 3/10\n",
            "\u001b[1m1544/1544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 1.9115\n",
            "Epoch 4/10\n",
            "\u001b[1m1544/1544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 1.7795\n",
            "Epoch 5/10\n",
            "\u001b[1m1544/1544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 1.6979\n",
            "Epoch 6/10\n",
            "\u001b[1m1544/1544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - loss: 1.6402\n",
            "Epoch 7/10\n",
            "\u001b[1m1544/1544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 1.5875\n",
            "Epoch 8/10\n",
            "\u001b[1m1544/1544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 1.5468\n",
            "Epoch 9/10\n",
            "\u001b[1m1544/1544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - loss: 1.5110\n",
            "Epoch 10/10\n",
            "\u001b[1m1544/1544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 1.4819\n",
            "Обучение GPT модели завершено!\n"
          ]
        }
      ],
      "source": [
        "# Создание GPT модели\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding\n",
        "\n",
        "# Параметры модели\n",
        "embed_dim = 128\n",
        "num_heads = 4\n",
        "ff_dim = 256\n",
        "num_layers = 4\n",
        "\n",
        "print(f\"Создаем GPT модель с параметрами:\")\n",
        "print(f\"- Размерность эмбеддинга: {embed_dim}\")\n",
        "print(f\"- Количество голов внимания: {num_heads}\")\n",
        "print(f\"- Размерность feed-forward: {ff_dim}\")\n",
        "print(f\"- Количество слоев: {num_layers}\")\n",
        "\n",
        "# Создание модели\n",
        "inp = Input(shape=(context_len,))\n",
        "x = Embedding(vocab_size, embed_dim)(inp)\n",
        "x = PositionalEncoding(context_len, embed_dim)(x)\n",
        "\n",
        "# Добавляем блоки Transformer\n",
        "for i in range(num_layers):\n",
        "    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
        "\n",
        "# Выходной слой для предсказания следующего токена\n",
        "out = Dense(vocab_size, activation=\"softmax\")(x[:, -1, :])\n",
        "\n",
        "gpt_model = Model(inputs=inp, outputs=out)\n",
        "gpt_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "print(\"Архитектура GPT модели:\")\n",
        "gpt_model.summary()\n",
        "\n",
        "# Обучение модели\n",
        "print(\"Начинаем обучение GPT модели...\")\n",
        "print(\"Внимание: Обучение может занять значительное время!\")\n",
        "\n",
        "gpt_model.fit(X, y, batch_size=128, epochs=10)\n",
        "\n",
        "print(\"Обучение GPT модели завершено!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k-BcvAlpJv4p"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4AKShzA93ct",
        "outputId": "7fc73fbe-f055-453d-ded5-2ecc92e07dab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Генерация текста с GPT моделью:\n",
            "Начальное слово: 'гарри'\n",
            "гарри с этинируев их гермионё чекала макгонагалл бынеи под серьёзно хорошо её пол, что одни, которой из, мистер поттер! ославне, и поднас, мистер результет. на людей шутки, потому, ведь ты чуть случайной. уюдишь, его снавидают широко о вама секрешите мог мартиах поттер! гарри что?!е поттер! ум? наконец де\n",
            "\n",
            "Генерация с другим начальным словом:\n",
            "Начальное слово: 'гарри' (короткая генерация)\n",
            "гарри мысего она родить говориру! называет ту,\n"
          ]
        }
      ],
      "source": [
        "def generate_gpt(seed_text, length=300, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Функция генерации текста с помощью GPT модели\n",
        "\n",
        "    Args:\n",
        "        seed_text (str): Начальный текст\n",
        "        length (int): Длина генерируемого текста\n",
        "        temperature (float): Температура сэмплирования\n",
        "\n",
        "    Returns:\n",
        "        str: Сгенерированный текст\n",
        "    \"\"\"\n",
        "    generated = seed_text\n",
        "    context = [char2idx.get(c, 0) for c in seed_text][-context_len:]\n",
        "\n",
        "    for _ in range(length):\n",
        "        # Подготавливаем входную последовательность\n",
        "        padded = pad_sequences([context], maxlen=context_len)\n",
        "        preds = gpt_model.predict(padded, verbose=0)[0]\n",
        "\n",
        "        # Безопасное масштабирование вероятностей\n",
        "        preds = np.asarray(preds).astype(\"float64\")\n",
        "        preds = np.log(np.clip(preds, 1e-8, 1.0)) / temperature\n",
        "        preds = np.exp(preds)\n",
        "        preds = preds / np.sum(preds)\n",
        "\n",
        "        # Выбираем следующий символ\n",
        "        next_idx = np.random.choice(len(preds), p=preds)\n",
        "        next_char = idx2char[next_idx]\n",
        "\n",
        "        generated += next_char\n",
        "        context.append(next_idx)\n",
        "        context = context[-context_len:]  # Сохраняем только последние context_len символов\n",
        "\n",
        "    return generated\n",
        "\n",
        "# Тестируем генерацию с GPT\n",
        "print(\"Генерация текста с GPT моделью:\")\n",
        "print(\"Начальное слово: 'гарри'\")\n",
        "generated_gpt = generate_gpt(\"гарри \", 300, temperature=1.0)\n",
        "print(generated_gpt)\n",
        "\n",
        "print(\"\\nГенерация с другим начальным словом:\")\n",
        "print(\"Начальное слово: 'гарри' (короткая генерация)\")\n",
        "generated_gpt_short = generate_gpt(\"гарри \", 40)\n",
        "print(generated_gpt_short)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRtW-8uT93ct"
      },
      "source": [
        "# Дообучение готовой GPT модели\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469,
          "referenced_widgets": [
            "9148e2049ae34b548958a9e96f32ce96",
            "34ff28660ebd4f89a1c490d4cf07293a",
            "51fad350fbed494ea41b5f91fa9f5a4d",
            "cc8a31b60c9841df96ffa5ada2aa2782",
            "de2750d183764ad88803d4ef8f86293c",
            "e6104af4da1e4bbfac5fc942c0e5936e",
            "c864b16e556c4aa29466e970bb60b24b",
            "8a3fb670e06340f2a086d0452e4e2ef5",
            "d0979c470a854cb68c4786915b9622cd",
            "669cb9b203e44d44a33ccec3e7c4c0f1",
            "a6cd3a4c7e814fb3a0864bbf7cb85b64",
            "c3387d7a8267414798f36c3929b09d03",
            "65ded35364744cbfab181d7e1cf63cad",
            "edd7c1e1470b4c0eb34b341f6290e08b",
            "f5ceaed5814446f89255e72d167bbf8a",
            "0f1f6217d0da4bb2904f82713348d835",
            "3d217095b573433b937db07d89ccaf93",
            "a9721cf8eee74892b796b43c0368d9f3",
            "8a9404b9e7a94521be349f00ea546bef",
            "0280d0328cb44c188fd4b8a6c776da9b",
            "5fa4f87f695b408991d063ab348b3dec",
            "e9811b4b6d9349fd8e4066e584bad1b6",
            "32929d91abde459f81070dbbadd7aff3",
            "83abb565afb5470e94bab544c748c25a",
            "bfd658374b5b46819a44e8b948c6723c",
            "656c6589b3634d8fa868616d8d766a6c",
            "76c8d8a78be14382bfce96ada1312e65",
            "a69d7fa405fa4d089acf7b68a1ee9ba9",
            "250de8d382e948ac807e0356ee3f2135",
            "2d0131ad320b4640aa4d29c4b32c3778",
            "e983f2aec89849dea74e7c99b5601ac7",
            "351ab219e118484db964e2d0bcf5e838",
            "c25298b5f4eb4925a4bf32e53527c59c",
            "6c9cefaad08a4dedae196d650ec29604",
            "e7f59cedf2894ada9a65abc7bae10a2e",
            "a853f17fd94b40d8b5bbd01d1b038b2b",
            "22ddfe146066449eafe0d613f8cb0750",
            "bb8542e85512470e99a81c2d6f2c9d83",
            "0897f6de28cd4b0eba12ab8232407d20",
            "f9e6be915f5848b7a5c50c1d7ec0b1a3",
            "fd295fe1788c4058b131efb31a05d939",
            "deed082298b04633a67a3e97dbd39a83",
            "972d3c9e44174e0a9289c541e24559c9",
            "2043c2f873fb41e487b70ba490498c9a",
            "4cbad8ac0b514e52adb2ecf63f47a5c5",
            "e943a61f3a494a7c97de2d8edadac2cf",
            "65a456066efe416a865d92d70baa1126",
            "c290bf078fca47e3a04101bd339bd681",
            "ff90b513461947db9a8670a231f780c8",
            "74d3d44e3d6e43a5aed1fd36d3de6c45",
            "193d364be3aa4bd6b88deba60806f3e6",
            "82d75e22670b44229f3cc03de53b1991",
            "d51f63a681c246aba91b3491892c3a91",
            "b937f7bd42fa46b68776eba6f540d03b",
            "6e0115d5ef704ffe8ddde6a40f1df76b",
            "a86d12243e1e4851933eedbffe8adaa3",
            "3af49965096748cfa2fc92c1e60192a9",
            "70fa4326c52d471b9a1aaab4b687a337",
            "6f7290bd21174bc697ef37bcfcfb75bc",
            "01925ccc66e54696b889bee9b01f3c0a",
            "26f0e8d4c34c47239ecce809919766d8",
            "fff06c2f85cb49eeba1470a0b9c9fe85",
            "d6ca2fa88b354c86b0e417c539c92bd9",
            "297936972959439c9496d70c72212c8f",
            "ab2fe8d835fc49268d4d59bf8434a973",
            "821ad8f83cf84d0799531732f568fee0",
            "de5de0f2a0c3453ca27a1945f5d57244",
            "387bb88cc72e4c5690c536047f20c07a",
            "0baa8fb7f5744e49b4d042628131c1ae",
            "e786342ecb9846f6a054bd4fc0cc9134",
            "d861fff42ef640a8920d7990251dd10a",
            "b40d3d26fb084897aa521970659a25fb",
            "f7a60d9d947a4d329a5a1acbed9d27da",
            "352e416f792f43e69be2c6a19bf8e4bc",
            "5c9a683bf05943f2b7e8fb4d40c7cfc5",
            "743b7b7169f649d4b5eb64a013c0dffd",
            "3ced86f482c4476eba78302fb60617af"
          ]
        },
        "id": "-5IeF4Hz93ct",
        "outputId": "07e5731d-fafe-4977-ecdf-b21ade6be3e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Библиотеки transformers и datasets уже установлены\n",
            "Настраиваем дообучение готовой GPT модели...\n",
            "Создан датасет с 10 записями\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9148e2049ae34b548958a9e96f32ce96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3387d7a8267414798f36c3929b09d03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32929d91abde459f81070dbbadd7aff3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/574 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c9cefaad08a4dedae196d650ec29604"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cbad8ac0b514e52adb2ecf63f47a5c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Датасет токенизирован!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a86d12243e1e4851933eedbffe8adaa3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/551M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de5de0f2a0c3453ca27a1945f5d57244"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предобученная модель загружена!\n",
            "Размер модели: 125,226,240 параметров\n"
          ]
        }
      ],
      "source": [
        "# Установка библиотек для дообучения\n",
        "try:\n",
        "    from datasets import Dataset\n",
        "    from transformers import GPT2Tokenizer, GPT2LMHeadModel, TrainingArguments, Trainer\n",
        "    print(\"Библиотеки transformers и datasets уже установлены\")\n",
        "except ImportError:\n",
        "    print(\"Устанавливаем необходимые библиотеки...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"transformers\", \"datasets\"])\n",
        "    from datasets import Dataset\n",
        "    from transformers import GPT2Tokenizer, GPT2LMHeadModel, TrainingArguments, Trainer\n",
        "\n",
        "print(\"Настраиваем дообучение готовой GPT модели...\")\n",
        "\n",
        "# Создание датасета из наших данных\n",
        "dataset = Dataset.from_pandas(df[[\"text\"]])\n",
        "\n",
        "print(f\"Создан датасет с {len(dataset)} записями\")\n",
        "\n",
        "# Загрузка предобученного токенизатора для русского языка\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    \"\"\"\n",
        "    Функция токенизации для датасета\n",
        "    \"\"\"\n",
        "    encodings = tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
        "    encodings[\"labels\"] = encodings[\"input_ids\"].copy()\n",
        "    return encodings\n",
        "\n",
        "# Токенизация датасета\n",
        "tokenized = dataset.map(tokenize_fn, batched=True)\n",
        "\n",
        "print(\"Датасет токенизирован!\")\n",
        "\n",
        "# Загрузка предобученной модели\n",
        "model = GPT2LMHeadModel.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "print(\"Предобученная модель загружена!\")\n",
        "print(f\"Размер модели: {model.num_parameters():,} параметров\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "Q77kdt6O93ct",
        "outputId": "46a3ecbe-cfa3-4b4a-83a4-6af1687f020a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1728070381.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаем дообучение модели...\n",
            "Это может занять значительное время!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnarzievtakdiralirus\u001b[0m (\u001b[33mnarzievtakdiralirus-1\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250924_195939-er824i0y</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/narzievtakdiralirus-1/huggingface/runs/er824i0y' target=\"_blank\">volcanic-breeze-1</a></strong> to <a href='https://wandb.ai/narzievtakdiralirus-1/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/narzievtakdiralirus-1/huggingface' target=\"_blank\">https://wandb.ai/narzievtakdiralirus-1/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/narzievtakdiralirus-1/huggingface/runs/er824i0y' target=\"_blank\">https://wandb.ai/narzievtakdiralirus-1/huggingface/runs/er824i0y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 01:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дообучение завершено!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline для генерации создан!\n",
            "Генерация текста с дообученной моделью:\n",
            "Начальная фраза: 'в хогвартсе'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "в хогвартсе&quot; и &quot;Древняя магия&quot; не было. Я бы хотел, чтобы кто-то объяснил этот феномен. Может быть, я и не понимаю его, но, думаю, понимаю. Я хочу, чтобы всё в моей жизни наладилась.\n",
            "\n",
            "\n",
            "\n",
            "16626831\tvalerianka\t2019-10-04 22:55:00\tДРЕВНЕМНАЯ МАГИЯ. Глава 1. Тёмный лес.   \\t&nbsp;   \\t&nbsp;   \\t&nbsp;  \\t&nbsp; \\t&nbsp;  \\t&nbsp; \\t&nbsp; \\t \\t \\t   \\t&nbsp;   \\t \\t \\t&nbsp;  \\t&nbsp; \\t&nbsp;   \\t&nbsp;  \\t&nbsp;  \\t&nbsp; \\t&nbsp; \\t&nbsp; \\t&nbsp;  \\t&nbsp; \\t&nbsp;  \\t&nbsp;  \\t&nbsp; \\t \\t \\t \\t   \\t \\t \\t \\t \\t \\t \\t \\t \\t\n",
            "\n",
            "Генерация с другой фразой:\n",
            "Начальная фраза: 'гермиона сказала'\n",
            "гермиона сказала: «Вы должны были понять это раньше, в самом начале». Но не было ни секунды, чтобы понять это. И вам было просто стыдно за то, что вы делаете такую глупость. Мы должны дать объяснение, что привело вас к смерти!\n",
            "\n",
            "Брайен! Брайан! Ты должен это видеть! Тебе нужно научиться говорить правду! Ты должен знать это! Брайан! Ты не должен был умирать! Не должен умирать, и ты должен был это выяснить и признать! И хотя ты очень молод, у тебя было не просто быть молодым, ты должен был стать взрослым! Ты должен был иметь возможность жить! И чтобы найти ответы, нужны были не только знания об этом, ты должен был научиться слушать собеседника! Ты должен был научиться использовать время, которое у тебя есть, в мирных целях, чтобы выжить, ты должен научиться выживать во все больше и больше опасностях, а потом вернуться, не сказав об этом больше!\n",
            "\n",
            "Взбесившиеся псы начали затихать. Они не хотели, чтобы они понимали это! Но, кажется, вы поняли то, что я сказала, доктор?! Я хочу знать, почему ты был так категоричен в моей просьбе!\n",
            "\n",
            "Брайен улыбнулся. Ему хотелось, чтобы псы понимали это раньше, в самом начале. «Я знал\n"
          ]
        }
      ],
      "source": [
        "# Настройка параметров обучения\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./rugpt-finetuned\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=50,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "# Создание тренера\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"Начинаем дообучение модели...\")\n",
        "print(\"Это может занять значительное время!\")\n",
        "\n",
        "# Запуск обучения\n",
        "trainer.train()\n",
        "\n",
        "print(\"Дообучение завершено!\")\n",
        "\n",
        "# Создание pipeline для генерации\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "print(\"Pipeline для генерации создан!\")\n",
        "\n",
        "# Тестируем генерацию с дообученной моделью\n",
        "print(\"Генерация текста с дообученной моделью:\")\n",
        "print(\"Начальная фраза: 'в хогвартсе'\")\n",
        "generated_finetuned = generator(\"в хогвартсе\", max_length=100, do_sample=True, temperature=0.9)\n",
        "print(generated_finetuned[0]['generated_text'])\n",
        "\n",
        "print(\"\\nГенерация с другой фразой:\")\n",
        "print(\"Начальная фраза: 'гермиона сказала'\")\n",
        "generated_finetuned2 = generator(\"гермиона сказала\", max_length=100, do_sample=True, temperature=1.0)\n",
        "print(generated_finetuned2[0]['generated_text'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d8OtT_593cu"
      },
      "source": [
        "# Заключение и сравнение моделей\n",
        "\n",
        "## Анализ результатов генерации\n",
        "\n",
        "В данной лабораторной работе мы реализовали и протестировали различные подходы к генерации текста:\n",
        "\n",
        "### 1. Simple RNN\n",
        "- **Преимущества**: Простота реализации, быстрая тренировка\n",
        "- **Недостатки**: Проблема исчезающего градиента, плохое качество генерации\n",
        "- **Применение**: Базовый уровень для понимания принципов работы\n",
        "\n",
        "### 2. LSTM (однонаправленная и многослойная)\n",
        "- **Преимущества**: Решение проблемы долгосрочных зависимостей, лучшее качество генерации\n",
        "- **Недостатки**: Медленная тренировка, ограниченная контекстная память\n",
        "- **Применение**: Хорошо подходит для последовательностей средней длины\n",
        "\n",
        "### 3. Bidirectional LSTM\n",
        "- **Преимущества**: Двунаправленная обработка контекста\n",
        "- **Недостатки**: Не подходит для генерации в реальном времени\n",
        "- **Применение**: Анализ и понимание текста, но не генерация\n",
        "\n",
        "### 4. GPT-style Transformer\n",
        "- **Преимущества**: Параллельная обработка, механизм внимания, высокое качество\n",
        "- **Недостатки**: Требует много вычислительных ресурсов\n",
        "- **Применение**: Современный стандарт для генерации текста\n",
        "\n",
        "### 5. Дообучение готовых моделей\n",
        "- **Преимущества**: Использование предобученных знаний, быстрое дообучение\n",
        "- **Недостатки**: Зависимость от качества предобученной модели\n",
        "- **Применение**: Практический подход для реальных задач\n",
        "\n",
        "## Рекомендации по выбору архитектуры\n",
        "\n",
        "- **Для изучения**: Начните с Simple RNN, затем переходите к LSTM\n",
        "- **Для экспериментов**: Используйте LSTM с различными токенизациями\n",
        "- **Для производства**: Рассмотрите Transformer архитектуры или дообучение готовых моделей\n",
        "- **Для русского языка**: Предпочтительно использовать предобученные модели с дообучением\n",
        "\n",
        "## Дальнейшее развитие\n",
        "\n",
        "1. **Увеличение размера модели**: Больше параметров = лучшее качество\n",
        "2. **Улучшение токенизации**: BPE, SentencePiece, современные методы\n",
        "3. **Оптимизация обучения**: Learning rate scheduling, gradient clipping\n",
        "4. **Оценка качества**: BLEU, ROUGE, человеческая оценка\n",
        "5. **Специализация**: Модели для конкретных доменов или стилей\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Bo2XpxDm93cu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9148e2049ae34b548958a9e96f32ce96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34ff28660ebd4f89a1c490d4cf07293a",
              "IPY_MODEL_51fad350fbed494ea41b5f91fa9f5a4d",
              "IPY_MODEL_cc8a31b60c9841df96ffa5ada2aa2782"
            ],
            "layout": "IPY_MODEL_de2750d183764ad88803d4ef8f86293c"
          }
        },
        "34ff28660ebd4f89a1c490d4cf07293a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6104af4da1e4bbfac5fc942c0e5936e",
            "placeholder": "​",
            "style": "IPY_MODEL_c864b16e556c4aa29466e970bb60b24b",
            "value": "tokenizer_config.json: "
          }
        },
        "51fad350fbed494ea41b5f91fa9f5a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a3fb670e06340f2a086d0452e4e2ef5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0979c470a854cb68c4786915b9622cd",
            "value": 1
          }
        },
        "cc8a31b60c9841df96ffa5ada2aa2782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_669cb9b203e44d44a33ccec3e7c4c0f1",
            "placeholder": "​",
            "style": "IPY_MODEL_a6cd3a4c7e814fb3a0864bbf7cb85b64",
            "value": " 1.25k/? [00:00&lt;00:00, 106kB/s]"
          }
        },
        "de2750d183764ad88803d4ef8f86293c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6104af4da1e4bbfac5fc942c0e5936e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c864b16e556c4aa29466e970bb60b24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a3fb670e06340f2a086d0452e4e2ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d0979c470a854cb68c4786915b9622cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "669cb9b203e44d44a33ccec3e7c4c0f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6cd3a4c7e814fb3a0864bbf7cb85b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3387d7a8267414798f36c3929b09d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65ded35364744cbfab181d7e1cf63cad",
              "IPY_MODEL_edd7c1e1470b4c0eb34b341f6290e08b",
              "IPY_MODEL_f5ceaed5814446f89255e72d167bbf8a"
            ],
            "layout": "IPY_MODEL_0f1f6217d0da4bb2904f82713348d835"
          }
        },
        "65ded35364744cbfab181d7e1cf63cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d217095b573433b937db07d89ccaf93",
            "placeholder": "​",
            "style": "IPY_MODEL_a9721cf8eee74892b796b43c0368d9f3",
            "value": "vocab.json: "
          }
        },
        "edd7c1e1470b4c0eb34b341f6290e08b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a9404b9e7a94521be349f00ea546bef",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0280d0328cb44c188fd4b8a6c776da9b",
            "value": 1
          }
        },
        "f5ceaed5814446f89255e72d167bbf8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fa4f87f695b408991d063ab348b3dec",
            "placeholder": "​",
            "style": "IPY_MODEL_e9811b4b6d9349fd8e4066e584bad1b6",
            "value": " 1.71M/? [00:00&lt;00:00, 67.2MB/s]"
          }
        },
        "0f1f6217d0da4bb2904f82713348d835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d217095b573433b937db07d89ccaf93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9721cf8eee74892b796b43c0368d9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a9404b9e7a94521be349f00ea546bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0280d0328cb44c188fd4b8a6c776da9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fa4f87f695b408991d063ab348b3dec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9811b4b6d9349fd8e4066e584bad1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32929d91abde459f81070dbbadd7aff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83abb565afb5470e94bab544c748c25a",
              "IPY_MODEL_bfd658374b5b46819a44e8b948c6723c",
              "IPY_MODEL_656c6589b3634d8fa868616d8d766a6c"
            ],
            "layout": "IPY_MODEL_76c8d8a78be14382bfce96ada1312e65"
          }
        },
        "83abb565afb5470e94bab544c748c25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a69d7fa405fa4d089acf7b68a1ee9ba9",
            "placeholder": "​",
            "style": "IPY_MODEL_250de8d382e948ac807e0356ee3f2135",
            "value": "merges.txt: "
          }
        },
        "bfd658374b5b46819a44e8b948c6723c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d0131ad320b4640aa4d29c4b32c3778",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e983f2aec89849dea74e7c99b5601ac7",
            "value": 1
          }
        },
        "656c6589b3634d8fa868616d8d766a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_351ab219e118484db964e2d0bcf5e838",
            "placeholder": "​",
            "style": "IPY_MODEL_c25298b5f4eb4925a4bf32e53527c59c",
            "value": " 1.27M/? [00:00&lt;00:00, 48.7MB/s]"
          }
        },
        "76c8d8a78be14382bfce96ada1312e65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a69d7fa405fa4d089acf7b68a1ee9ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "250de8d382e948ac807e0356ee3f2135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d0131ad320b4640aa4d29c4b32c3778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e983f2aec89849dea74e7c99b5601ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "351ab219e118484db964e2d0bcf5e838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c25298b5f4eb4925a4bf32e53527c59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c9cefaad08a4dedae196d650ec29604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7f59cedf2894ada9a65abc7bae10a2e",
              "IPY_MODEL_a853f17fd94b40d8b5bbd01d1b038b2b",
              "IPY_MODEL_22ddfe146066449eafe0d613f8cb0750"
            ],
            "layout": "IPY_MODEL_bb8542e85512470e99a81c2d6f2c9d83"
          }
        },
        "e7f59cedf2894ada9a65abc7bae10a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0897f6de28cd4b0eba12ab8232407d20",
            "placeholder": "​",
            "style": "IPY_MODEL_f9e6be915f5848b7a5c50c1d7ec0b1a3",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a853f17fd94b40d8b5bbd01d1b038b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd295fe1788c4058b131efb31a05d939",
            "max": 574,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_deed082298b04633a67a3e97dbd39a83",
            "value": 574
          }
        },
        "22ddfe146066449eafe0d613f8cb0750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972d3c9e44174e0a9289c541e24559c9",
            "placeholder": "​",
            "style": "IPY_MODEL_2043c2f873fb41e487b70ba490498c9a",
            "value": " 574/574 [00:00&lt;00:00, 55.3kB/s]"
          }
        },
        "bb8542e85512470e99a81c2d6f2c9d83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0897f6de28cd4b0eba12ab8232407d20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9e6be915f5848b7a5c50c1d7ec0b1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd295fe1788c4058b131efb31a05d939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deed082298b04633a67a3e97dbd39a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "972d3c9e44174e0a9289c541e24559c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2043c2f873fb41e487b70ba490498c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cbad8ac0b514e52adb2ecf63f47a5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e943a61f3a494a7c97de2d8edadac2cf",
              "IPY_MODEL_65a456066efe416a865d92d70baa1126",
              "IPY_MODEL_c290bf078fca47e3a04101bd339bd681"
            ],
            "layout": "IPY_MODEL_ff90b513461947db9a8670a231f780c8"
          }
        },
        "e943a61f3a494a7c97de2d8edadac2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d3d44e3d6e43a5aed1fd36d3de6c45",
            "placeholder": "​",
            "style": "IPY_MODEL_193d364be3aa4bd6b88deba60806f3e6",
            "value": "Map: 100%"
          }
        },
        "65a456066efe416a865d92d70baa1126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82d75e22670b44229f3cc03de53b1991",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d51f63a681c246aba91b3491892c3a91",
            "value": 10
          }
        },
        "c290bf078fca47e3a04101bd339bd681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b937f7bd42fa46b68776eba6f540d03b",
            "placeholder": "​",
            "style": "IPY_MODEL_6e0115d5ef704ffe8ddde6a40f1df76b",
            "value": " 10/10 [00:00&lt;00:00, 10.26 examples/s]"
          }
        },
        "ff90b513461947db9a8670a231f780c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d3d44e3d6e43a5aed1fd36d3de6c45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "193d364be3aa4bd6b88deba60806f3e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82d75e22670b44229f3cc03de53b1991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d51f63a681c246aba91b3491892c3a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b937f7bd42fa46b68776eba6f540d03b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e0115d5ef704ffe8ddde6a40f1df76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a86d12243e1e4851933eedbffe8adaa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3af49965096748cfa2fc92c1e60192a9",
              "IPY_MODEL_70fa4326c52d471b9a1aaab4b687a337",
              "IPY_MODEL_6f7290bd21174bc697ef37bcfcfb75bc"
            ],
            "layout": "IPY_MODEL_01925ccc66e54696b889bee9b01f3c0a"
          }
        },
        "3af49965096748cfa2fc92c1e60192a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26f0e8d4c34c47239ecce809919766d8",
            "placeholder": "​",
            "style": "IPY_MODEL_fff06c2f85cb49eeba1470a0b9c9fe85",
            "value": "config.json: 100%"
          }
        },
        "70fa4326c52d471b9a1aaab4b687a337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ca2fa88b354c86b0e417c539c92bd9",
            "max": 720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_297936972959439c9496d70c72212c8f",
            "value": 720
          }
        },
        "6f7290bd21174bc697ef37bcfcfb75bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab2fe8d835fc49268d4d59bf8434a973",
            "placeholder": "​",
            "style": "IPY_MODEL_821ad8f83cf84d0799531732f568fee0",
            "value": " 720/720 [00:00&lt;00:00, 94.0kB/s]"
          }
        },
        "01925ccc66e54696b889bee9b01f3c0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26f0e8d4c34c47239ecce809919766d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff06c2f85cb49eeba1470a0b9c9fe85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6ca2fa88b354c86b0e417c539c92bd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "297936972959439c9496d70c72212c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab2fe8d835fc49268d4d59bf8434a973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821ad8f83cf84d0799531732f568fee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de5de0f2a0c3453ca27a1945f5d57244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_387bb88cc72e4c5690c536047f20c07a",
              "IPY_MODEL_0baa8fb7f5744e49b4d042628131c1ae",
              "IPY_MODEL_e786342ecb9846f6a054bd4fc0cc9134"
            ],
            "layout": "IPY_MODEL_d861fff42ef640a8920d7990251dd10a"
          }
        },
        "387bb88cc72e4c5690c536047f20c07a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b40d3d26fb084897aa521970659a25fb",
            "placeholder": "​",
            "style": "IPY_MODEL_f7a60d9d947a4d329a5a1acbed9d27da",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "0baa8fb7f5744e49b4d042628131c1ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_352e416f792f43e69be2c6a19bf8e4bc",
            "max": 551290714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c9a683bf05943f2b7e8fb4d40c7cfc5",
            "value": 551290714
          }
        },
        "e786342ecb9846f6a054bd4fc0cc9134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_743b7b7169f649d4b5eb64a013c0dffd",
            "placeholder": "​",
            "style": "IPY_MODEL_3ced86f482c4476eba78302fb60617af",
            "value": " 551M/551M [00:20&lt;00:00, 22.2MB/s]"
          }
        },
        "d861fff42ef640a8920d7990251dd10a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40d3d26fb084897aa521970659a25fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7a60d9d947a4d329a5a1acbed9d27da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "352e416f792f43e69be2c6a19bf8e4bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9a683bf05943f2b7e8fb4d40c7cfc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "743b7b7169f649d4b5eb64a013c0dffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ced86f482c4476eba78302fb60617af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}