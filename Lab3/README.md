# Генеративные нейросети для текстовой генерации

## Описание проекта

Данная лабораторная работа посвящена исследованию и сравнению различных архитектур генеративных нейронных сетей для создания текстового контента. Проект включает изучение современных методов обработки естественного языка и генерации последовательностей.

## Задачи лабораторной работы

Необходимо обучить и сравнить качество нескольких генеративных текстовых моделей на выбранном текстовом датасете.

### Исследуемые архитектуры:

1. **Simple RNN** с посимвольной и по-словной токенизацией
2. **Однонаправленная LSTM** (однослойная и многослойная) с различными типами токенизации:
   - Посимвольная токенизация
   - Токенизация по словам
   - Токенизация на основе BPE (Byte Pair Encoding)
3. **Двунаправленная LSTM** для улучшения понимания контекста
4. **[Дополнительно]** Трансформерная архитектура (GPT) "с нуля"
5. **[Дополнительно]** До-обучение предобученной GPT-сети

## Выбор датасета

Рекомендуется использовать один из следующих текстовых корпусов:

### Литературные произведения
- **Английская литература** с сайта [Project Gutenberg](https://www.gutenberg.org/)
- **Русская литература** с сайта [lib.ru](http://lib.ru)
- **Гарри Поттер и методы рационального мышления** ([hpmor.ru](https://hpmor.ru/))

### Специализированные датасеты
- **Архивы конференций FIDONet** ([archive.org](https://archive.org/download/usenet-fido7.ru))
- **Англоязычные книги Wikibooks** ([Kaggle](https://www.kaggle.com/datasets/dhruvildave/wikibooks-dataset))
- **Русскоязычные книги Wikibooks** ([Kaggle](https://www.kaggle.com/datasets/dhruvildave/wikibooks-dataset))
- **Статьи Medium** ([Kaggle](https://www.kaggle.com/datasets/fabiochiusano/medium-articles))
- **Субтитры фильмов** ([Kaggle](https://www.kaggle.com/datasets/adiamaan/movie-subtitle-dataset))

### Альтернативные задачи
> **Для отличной оценки**: Можно исследовать генерацию последовательностей, отличных от текста, например музыкальных файлов в формате MIDI, которые содержат последовательности нот.

## Технические требования

### Основные библиотеки
- **PyTorch** или **TensorFlow/Keras** для реализации моделей
- **Transformers** для работы с предобученными моделями
- **NLTK** или **spaCy** для обработки текста
- **NumPy** и **Pandas** для работы с данными

### Архитектурные компоненты
- **RNN/LSTM/GRU** слои для последовательного моделирования
- **Attention механизмы** для улучшения качества генерации
- **Embedding слои** для представления токенов
- **Dropout и BatchNorm** для регуляризации

## Структура проекта

- `Lab3_NLP_Text_Generation.ipynb` - основной ноутбук с реализацией и экспериментами
- `requirements.txt` - список необходимых зависимостей
- `README.md` - описание проекта и инструкции

## Методология оценки

### Количественные метрики
- **Perplexity** - основная метрика качества языковой модели
- **BLEU Score** - оценка качества сгенерированного текста
- **ROUGE Score** - метрика для оценки связности текста

### Качественная оценка
- **Связность текста** - логическая последовательность предложений
- **Грамматическая корректность** - правильность построения фраз
- **Семантическая осмысленность** - соответствие контексту

## Ожидаемые результаты

### Сравнительный анализ
- Таблица сравнения метрик для различных архитектур
- Графики обучения (loss, perplexity)
- Примеры сгенерированного текста для каждой модели

### Выводы и рекомендации
- Анализ преимуществ и недостатков каждой архитектуры
- Рекомендации по выбору модели для конкретных задач
- Предложения по улучшению качества генерации

## Дополнительные возможности

### Продвинутые техники
- **Beam Search** для улучшения качества генерации
- **Temperature Sampling** для контроля креативности
- **Top-k и Top-p sampling** для разнообразия вывода

### Оптимизация
- **Gradient Clipping** для стабилизации обучения
- **Learning Rate Scheduling** для улучшения сходимости
- **Early Stopping** для предотвращения переобучения

## Отчётность

Результаты работы должны быть оформлены в файле `REPORT.md` и включать:

1. **Описание выбранного датасета** и его характеристик
2. **Детальное описание архитектур** всех реализованных моделей
3. **Результаты экспериментов** с количественными и качественными метриками
4. **Сравнительный анализ** различных подходов
5. **Выводы и рекомендации** для практического применения

## Полезные ресурсы

- [Keras Text Generation Examples](https://keras.io/examples/generative/)
- [Hugging Face Transformers](https://huggingface.co/transformers/)
- [OpenAI GPT Documentation](https://platform.openai.com/docs/models/gpt-3-5)
- [Byte Pair Encoding Tutorial](https://keras.io/api/keras_nlp/tokenizers/byte_pair_tokenizer/)

---

