# Отчёт по лабораторной работе
## Свёрточные нейронные сети

### Команда проекта:

| ФИО                 |           Роль в проекте           | Оценка       |
|---------------------|------------------------------------|--------------|
| Крижановская А.А.   |         Делала весь проект         |              |

> *Комментарии проверяющего*

---

# Лабораторная работа №1: Классификация пород кошек и собак по лицу

## Цель работы
Разработка и сравнение моделей **бинарной** и **многоклассовой** классификации изображений домашних животных с использованием сверточных нейронных сетей.

## 1. Бинарная классификация (кошки vs собаки)

### Подготовка данных
- **Размер изображений**: 224×224 пикселей
- **Аугментации для обучающей выборки**:
  - Случайное вращение (±20°)
  - Случайное масштабирование и обрезка
  - Случайное горизонтальное отражение
  - Изменение яркости/контраста/насыщенности/оттенка
- **Нормализация**: ImageNet mean/std

### Архитектура модели
```python
class ConvNet(nn.Module):
    def __init__(self):
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)    # Первый свёрточный слой
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)   # Второй свёрточный слой
        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)   # Третий свёрточный слой
        self.fc1 = nn.Linear(64*28*28, 512)             # Первый полносвязный слой
        self.fc2 = nn.Linear(512, 2)                    # Выходной слой (2 класса)
```

### Результаты обучения

| Epoch | Train Loss | Train Acc | Test Loss | Test Acc |
|-------|------------|-----------|-----------|----------|
| 1     | 0.6448     | 65.15%    | 0.6271    | 65.60%   |
| 5     | 0.6116     | 67.07%    | 0.5813    | 68.65%   |
| 10    | 0.6040     | 68.32%    | 0.5484    | 72.63%   |

**Финальные метрики:**
- **Test Accuracy**: 72.63%
- **Confusion Matrix**: Сбалансированное качество на обоих классах
- **Сходимость**: Стабильное улучшение в течение обучения

---

## 2. Многоклассовая классификация (35 пород)

### Подготовка данных
- **Аналогичные трансформации** как для бинарной классификации
- **Разделение на train/test**: 80/20
- **Количество классов**: 35 пород животных

### Архитектура модели
Та же структура, но с измененным выходным слоем:
```python
self.fc2 = nn.Linear(512, 35)  # 35 классов вместо 2
```

### Результаты обучения

| Epoch | Train Loss | Train Acc | Test Loss | Test Acc |
|-------|------------|-----------|-----------|----------|
| 1     | 3.5147     | 5.36%     | 3.4356    | 6.57%    |
| 5     | 3.1941     | 11.69%    | 3.0076    | 18.50%   |
| 10    | 3.0186     | 16.07%    | 2.7352    | 23.09%   |

**Финальные метрики:**
- **Test Accuracy**: 23.09%
- **Top-3 Accuracy**: 47.25%
- **Confusion Matrix**: Неравномерное распределение ошибок между классами

### Визуализации
1. **Графики обучения**:
   - **Loss**: Хорошая сходимость для обеих задач
   - **Accuracy**: Стабильный рост точности
2. **Confusion Matrix**:
   - **Бинарная**: Сбалансированная матрица
   - **Многоклассовая**: Высокий разброс ошибок

---

## Выводы по Lab 1

### Бинарная классификация:
- Модель достигла **удовлетворительной точности 72.63%**
- Показала **хорошую сходимость** при обучении
- **Сбалансированное качество** на обоих классах

### Многоклассовая классификация:
- **Низкая точность (23.09%)** из-за сложности задачи
- **Top-3 accuracy почти в 2 раза выше (47.25%)**
- **Требуется более сложная архитектура** для улучшения

### Рекомендации:
- Использовать **Transfer Learning** (VGG/ResNet)
- Увеличить **количество эпох обучения**
- Применить **более агрессивные аугментации**
- Использовать **балансировку классов**

---

# Лабораторная работа №2: Классификация Oxford Pets

## Цель работы
Исследование и сравнение эффективности различных архитектур нейронных сетей (**VGG16**, **VGG19**, **ResNet50**) для задачи классификации пород домашних животных.

## 1. Предобработка данных

### Визуализация данных
Были загружены и визуализированы изображения из датасета:
```python
def visualize_pet_images(folder_path, num_images=5):
    # Код визуализации с красивым оформлением
```

### Статистика датасета
- **Общее количество изображений**: **7,390**
- **Количество изображений по породам**: ~200 на класс (37 классов)
- **Небольшой дисбаланс**: 
  - scottish_terrier: 199
  - staffordshire_bull_terrier: 191

### Разделение данных
- **Разделение на train/test**: 80/20:
  - **Train**: 5,914 изображений
  - **Test**: 1,479 изображений

---

## 2. Подготовка данных

Применены аугментации для обучающей выборки:
```python
train_transforms = transforms.Compose([
    transforms.Resize(224),                    # Изменение размера
    transforms.RandomRotation(20),            # Случайное вращение
    transforms.RandomResizedCrop(224),        # Случайное масштабирование
    transforms.RandomHorizontalFlip(),        # Горизонтальное отражение
    transforms.ColorJitter(...),              # Цветовые изменения
    transforms.ToTensor(),                    # Преобразование в тензор
    transforms.Normalize(...)                 # Нормализация
])
```

---

## 3. Модели

### Архитектуры
1. **VGG16** с доработанным классификатором
2. **VGG19** с доработанным классификатором  
3. **ResNet50** с доработанным классификатором

### Изменения в классификаторе:
```python
nn.Sequential(
    nn.Linear(num_features, 1024),    # Расширение признаков
    nn.ReLU(),                        # Активация
    nn.BatchNorm1d(1024),            # Батч-нормализация
    nn.Dropout(0.5),                 # Регуляризация
    nn.Linear(1024, num_classes),    # Выходной слой
    nn.Softmax(dim=1)                # Финальная активация
)
```

---

## 4. Обучение моделей

### Параметры обучения:
- **Оптимизатор**: SGD (lr=0.001, momentum=0.9)
- **Функция потерь**: CrossEntropyLoss
- **Количество эпох**: 10
- **Размер батча**: 32

### Результаты обучения

#### VGG16
| Epoch | Train Loss | Train Acc | Test Loss | Test Acc |
|-------|------------|-----------|-----------|----------|
| 10    | 3.1589     | 55.56%    | 2.9301    | 74.17%   |

#### VGG19
| Epoch | Train Loss | Train Acc | Test Loss | Test Acc |
|-------|------------|-----------|-----------|----------|
| 10    | 3.1190     | 60.18%    | 2.8828    | 81.00%   |

#### ResNet50
| Epoch | Train Loss | Train Acc | Test Loss | Test Acc |
|-------|------------|-----------|-----------|----------|
| 10    | 3.0136     | 70.24%    | 2.8412    | 83.77%   |

---

## 5. Оценка качества

### Финальные метрики:
- **VGG16**: Test Accuracy = **74.17%**
- **VGG19**: Test Accuracy = **81.00%**
- **ResNet50**: 
  - Test Accuracy = **83.77%**
  - Top-3 Accuracy = **90.94%**
  - Top-5 Accuracy = **93.37%**

---

## Выводы по Lab 2

### Сравнение моделей:
1. **ResNet50 показала наилучшие результаты** (83.77% точности)
2. **VGG19 показала себя лучше VGG16** (81.00% vs 74.17%)
3. **Все модели демонстрируют хорошую сходимость**, но ResNet50 обучается быстрее
4. **Метрики Top-3 и Top-5 подтверждают**, что модель часто дает правильный ответ среди первых вариантов

### Рекомендации для улучшения:
- **Увеличить количество эпох** обучения
- Использовать **более сложные аугментации**
- Применить **fine-tuning всех слоев**
- Добавить **более детальную визуализацию** (GradCAM)

---

# Лабораторная работа №3: Генерация изображений животных с помощью GAN

## Цель работы
Исследование возможностей **генеративно-состязательных сетей (GAN)** для создания реалистичных изображений морд домашних животных на основе датасета PetFaces.

## 1. Подготовка данных

### Датасет
- **Использован датасет**: PetFaces (35 классов животных)
- **Размер изображений**: 64×64 пикселей
- **Преобразования**:
  - Конвертация в RGB
  - Нормализация тензоров
- **Загрузчик данных**:
  - Batch size: 32
  - Shuffle: True

```python
transform = transforms.Compose([
    transforms.Resize((64, 64)),                    # Изменение размера
    transforms.Lambda(lambda x: x.convert('RGB')), # Конвертация в RGB
    transforms.ToTensor(),                         # Преобразование в тензор
])
```

---

## 2. Архитектура моделей

### Генератор
```python
class Generator(nn.Module):
    def __init__(self):
        # 4 слоя ConvTranspose2d с BatchNorm и ReLU
        # Вход: шум 100D -> выход: 3x64x64 (RGB изображение)
        # Активация: Tanh на выходе
```

**Архитектура:**
- **Вход**: 100D случайный шум
- **Выход**: 3×64×64 RGB изображение
- **Слои**: 4 деконволюционных слоя с BatchNorm
- **Активация**: ReLU (скрытые) + Tanh (выход)

### Дискриминатор
```python
class Discriminator(nn.Module):
    def __init__(self):
        # 4 полносвязных слоя с LeakyReLU и Dropout
        # Вход: 3x64x64 -> выход: 1 (вероятность реальности)
        # Активация: Sigmoid на выходе
```

**Архитектура:**
- **Вход**: 3×64×64 изображение
- **Выход**: 1 значение (вероятность)
- **Слои**: 4 полносвязных слоя с Dropout
- **Активация**: LeakyReLU (скрытые) + Sigmoid (выход)

### Дополнительные компоненты
- **Предобученный ResNet18** (фиксированные веса) для извлечения признаков
- **Оптимизаторы**: Adam (lr=0.0002, beta1=0.5)

---

## 3. Процесс обучения

### Параметры
- **Количество эпох**: 1000
- **Label smoothing**: 0.1
- **Градиентный клиппинг**: 1.0
- **Частота сохранения**: каждые 50 эпох

### Функция потерь
Бинарная кросс-энтропия:
```
L_D = BCE(D(x), 0.9) + BCE(D(G(z)), 0.1)
L_G = BCE(D(G(z)), 1.0)
```

### Динамика обучения
| Epoch | D Loss  | G Loss  |
|-------|---------|---------|
| 0     | 1.391   | 1.012   |
| 50    | 1.339   | 0.811   |
| 100   | 1.352   | 0.770   |

---

## 4. Результаты

### Визуализация
- **Генерируемые изображения** сохраняются в директорию `./res`
- **Промежуточные результаты** отображаются каждые 50 эпох
- **Пример сгенерированного изображения**:
  ![Пример](images/output.png)

### Качественная оценка
1. **На начальных этапах**: генерируются шумовые паттерны
2. **После 50 эпох**: начинают проявляться контуры морд животных
3. **Цветовая гамма**: соответствует исходному датасету

---

## 5. Выводы и рекомендации

### Успехи:
1. **GAN успешно обучается** генерировать изображения животных
2. **Качество улучшается** с каждой эпохой
3. **Стабилизация обучения** благодаря label smoothing и gradient clipping

### Основные проблемы:
1. **Недостаточная детализация** (64×64)
2. **Модальный коллапс** на поздних этапах
3. **Длительное время обучения** для качественных результатов

### Пути улучшения:
- **Увеличение разрешения** (128×128+)
- **Применение Progressive GAN**
- **Использование WGAN-GP** для стабилизации
- **Увеличение количества эпох**
- **Добавление само-внимания** в архитектуру

### Заключение:
Эксперимент подтвердил **возможность генерации изображений животных** с помощью GAN, однако для получения **фотореалистичных результатов** требуются более сложные архитектуры и большие вычислительные ресурсы.

---

## Общие выводы по всем лабораторным работам

### Сравнение подходов:

| Подход | Точность | Время обучения | Сложность | Рекомендация |
|--------|----------|----------------|-----------|--------------|
| **CNN с нуля** | 23-73% | Быстро | Низкая | Для простых задач |
| **Transfer Learning** | 74-84% | Средне | Средняя | **Лучший выбор** |
| **GAN** | Качественная генерация | Медленно | Высокая | Для креатива |

### Ключевые инсайты:
1. **Transfer Learning значительно превосходит** обучение с нуля
2. **ResNet архитектуры показывают лучшие результаты** по сравнению с VGG
3. **GAN требуют много времени**, но способны создавать интересные результаты
4. **Аугментация данных критически важна** для качества обучения

### Практические рекомендации:
- **Для продакшена**: Используйте Transfer Learning с ResNet
- **Для быстрого прототипирования**: CNN с нуля на малых данных  
- **Для творческих задач**: GAN с увеличенным разрешением
- **Всегда используйте аугментацию** и мониторинг метрик

**Лабораторная работа завершена успешно!**

