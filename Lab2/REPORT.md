# Отчёт по лабораторной работе
## Свёрточные нейронные сети и генеративные модели

### Информация о студенте:

| ФИО | Роль в проекте | Оценка |
|-----|----------------|--------|
| Крижановская А.А. | Разработка моделей, анализ данных, написание отчёта | |

> *Комментарии преподавателя*

---

# Часть 1 лабораторной работы №2: Классификация изображений домашних животных

## Цели и задачи

Создание и тестирование свёрточных нейронных сетей для решения задач классификации изображений кошек и собак. Исследование эффективности различных подходов к обработке визуальных данных.

## 1. Бинарная классификация (определение вида животного)

### Настройка данных
- Исходное разрешение: 224×224 пикселей
- Методы аугментации для обучения:
  - Произвольный поворот в диапазоне ±20°
  - Случайное изменение масштаба с обрезкой
  - Горизонтальное зеркальное отражение
  - Корректировка яркости и контрастности
- Стандартизация: средние значения и стандартные отклонения ImageNet

### Структура нейронной сети
```python
class PetClassificationCNN(nn.Module):
    def __init__(self):
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)
        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)
        self.fc1 = nn.Linear(64*28*28, 512)
        self.fc2 = nn.Linear(512, 2)
```

### Показатели обучения
| Эпоха | Потери (обучение) | Точность (обучение) | Потери (тест) | Точность (тест) |
|-------|-------------------|---------------------|---------------|-----------------|
| 1     | 0.6448            | 65.15%              | 0.6271        | 65.60%          |
| 10    | 0.6040            | 68.32%              | 0.5484        | 72.63%          |

**Итоговые результаты:**
- Точность на тестовой выборке: 72.63%
- Матрица ошибок демонстрирует равномерное качество для обоих классов

## 2. Многоклассовая классификация (определение породы)

### Подготовка данных
- Аналогичные трансформации изображений
- Разделение данных: 80% обучение, 20% тестирование
- Количество категорий: 35 пород

### Модификация архитектуры
Использована та же структура с изменённым выходным слоем:
```python
self.fc2 = nn.Linear(512, 35)
```

### Результаты обучения
| Эпоха | Потери (обучение) | Точность (обучение) | Потери (тест) | Точность (тест) |
|-------|-------------------|---------------------|---------------|-----------------|
| 1     | 3.5147            | 5.36%               | 3.4356        | 6.57%           |
| 10    | 3.0186            | 16.07%              | 2.7352        | 23.09%          |

**Итоговые метрики:**
- Точность на тестовой выборке: 23.09%
- Точность в топ-3: 47.25%
- Матрица ошибок показывает неравномерное распределение неточностей

## Анализ результатов

### Графики обучения
1. **Функция потерь**: демонстрирует сходимость для обеих задач
2. **Точность**: стабильное улучшение показателей
3. **Матрицы ошибок**:
   - Бинарная классификация: сбалансированное качество
   - Многоклассовая: значительный разброс ошибок

## Выводы по первой части

1. **Бинарная классификация**:
   - Достигнута приемлемая точность 72.63%
   - Показана хорошая сходимость алгоритма

2. **Многоклассовая классификация**:
   - Низкая точность (23.09%) обусловлена сложностью задачи
   - Точность в топ-3 значительно выше (47.25%)
   - Требуется более сложная архитектура

**Рекомендации для улучшения:**
- Применение transfer learning (VGG/ResNet)
- Увеличение продолжительности обучения
- Более агрессивные методы аугментации
- Балансировка классов

---

# Часть 2 лабораторной работы №2: Transfer Learning на Oxford Pets

## Цели исследования

Сравнительный анализ эффективности предобученных архитектур (VGG16, VGG19, ResNet50) для классификации пород домашних животных.

## 1. Анализ датасета

### Визуализация данных
Реализована функция для отображения образцов:
```python
def display_pet_images(folder_path, num_images=5):
    # Код визуализации
```

### Статистические характеристики
- Общий объём данных: **7390 изображений**
- Распределение по породам: ~200 образцов на класс (37 классов)
- Незначительный дисбаланс:
  - scottish_terrier: 199 изображений
  - staffordshire_bull_terrier: 191 изображение

### Разделение данных
- Пропорция train/test: 80/20
  - Обучающая выборка: 5914 изображений
  - Тестовая выборка: 1479 изображений

## 2. Предобработка данных

Применены аугментации для обучающей выборки:
```python
train_transforms = transforms.Compose([
    transforms.Resize(224),
    transforms.RandomRotation(20),
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(...),
    transforms.ToTensor(),
    transforms.Normalize(...)
])
```

## 3. Архитектуры моделей

### Используемые предобученные сети
1. **VGG16** с модифицированным классификатором
2. **VGG19** с модифицированным классификатором
3. **ResNet50** с модифицированным классификатором

### Структура классификатора
```python
nn.Sequential(
    nn.Linear(num_features, 1024),
    nn.ReLU(),
    nn.BatchNorm1d(1024),
    nn.Dropout(0.5),
    nn.Linear(1024, num_classes),
    nn.Softmax(dim=1)
)
```

## 4. Процесс обучения

### Параметры оптимизации
- Оптимизатор: SGD (lr=0.001, momentum=0.9)
- Функция потерь: CrossEntropyLoss
- Количество эпох: 10
- Размер батча: 32

### Результаты обучения

#### VGG16
| Эпоха | Потери (обучение) | Точность (обучение) | Потери (тест) | Точность (тест) |
|-------|-------------------|---------------------|---------------|-----------------|
| 10    | 3.1589            | 55.56%              | 2.9301        | 74.17%          |

#### VGG19
| Эпоха | Потери (обучение) | Точность (обучение) | Потери (тест) | Точность (тест) |
|-------|-------------------|---------------------|---------------|-----------------|
| 10    | 3.1190            | 60.18%              | 2.8828        | 81.00%          |

#### ResNet50
| Эпоха | Потери (обучение) | Точность (обучение) | Потери (тест) | Точность (тест) |
|-------|-------------------|---------------------|---------------|-----------------|
| 10    | 3.0136            | 70.24%              | 2.8412        | 83.77%          |

## 5. Оценка качества

### Финальные метрики
- **VGG16**: Точность на тесте = 74.17%
- **VGG19**: Точность на тесте = 81.00%
- **ResNet50**: 
  - Точность на тесте = 83.77%
  - Точность в топ-3 = 90.94%
  - Точность в топ-5 = 93.37%

## Выводы по второй части

1. Наилучшие результаты показала модель ResNet50 (83.77% точности)
2. VGG19 превзошла VGG16 (81.00% против 74.17%)
3. Все модели демонстрируют хорошую сходимость, ResNet50 обучается быстрее
4. Метрики топ-3 и топ-5 подтверждают, что модель часто даёт правильный ответ среди первых вариантов

**Рекомендации для улучшения:**
- Увеличение количества эпох обучения
- Применение более сложных аугментаций
- Fine-tuning всех слоёв модели

---

# Часть 3 лабораторной работы №2: Генерация изображений с помощью GAN

## Цели исследования

Исследование возможностей генеративно-состязательных сетей для создания реалистичных изображений морд домашних животных на основе датасета PetFaces.

## 1. Подготовка данных

### Характеристики датасета
- Использован датасет PetFaces (35 классов животных)
- Размер изображений: 64×64 пикселя
- Преобразования:
  - Конвертация в RGB
  - Нормализация тензоров
- Параметры загрузчика:
  - Размер батча: 32
  - Перемешивание: включено

```python
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.Lambda(lambda x: x.convert('RGB')),
    transforms.ToTensor(),
])
```

## 2. Архитектура моделей

### Генератор
```python
class ImageGenerator(nn.Module):
    def __init__(self):
        # 4 слоя ConvTranspose2d с BatchNorm и ReLU
        # Вход: шум 100D -> выход: 3x64x64 (RGB изображение)
        # Активация: Tanh на выходе
```

### Дискриминатор
```python
class ImageDiscriminator(nn.Module):
    def __init__(self):
        # 4 полносвязных слоя с LeakyReLU и Dropout
        # Вход: 3x64x64 -> выход: 1 (вероятность реальности)
        # Активация: Sigmoid на выходе
```

### Дополнительные компоненты
- Предобученный ResNet18 (фиксированные веса) для извлечения признаков
- Оптимизаторы: Adam (lr=0.0002, beta1=0.5)

## 3. Процесс обучения

### Параметры обучения
- Количество эпох: 1000
- Label smoothing: 0.1
- Градиентный клиппинг: 1.0
- Частота сохранения: каждые 50 эпох

### Функция потерь
Бинарная кросс-энтропия:
L_D = BCE(D(x), 0.9) + BCE(D(G(z)), 0.1)
L_G = BCE(D(G(z)), 1.0)

### Динамика обучения
| Эпоха | Потери D | Потери G |
|-------|----------|----------|
| 0     | 1.391    | 1.012    |
| 50    | 1.339    | 0.811    |

## 4. Результаты

### Визуализация
- Сгенерированные изображения сохраняются в директорию `./res`
- Промежуточные результаты отображаются каждые 50 эпох
- Пример сгенерированного изображения:
  ![Пример](images/output.png)

### Качественная оценка
1. На начальных этапах генерируются шумовые паттерны
2. После 50 эпох начинают проявляться контуры морд животных
3. Цветовая гамма соответствует исходному датасету

## 5. Выводы и рекомендации

1. GAN успешно обучается генерировать изображения животных
2. Основные проблемы:
   - Недостаточная детализация (64×64)
   - Модальный коллапс на поздних этапах
3. Пути улучшения:
   - Увеличение разрешения (128×128+)
   - Применение Progressive GAN
   - Использование WGAN-GP для стабилизации
   - Увеличение количества эпох
   - Добавление само-внимания в архитектуру

**Заключение:** Эксперимент подтвердил возможность генерации изображений животных с помощью GAN, однако для получения фотореалистичных результатов требуются более сложные архитектуры и большие вычислительные ресурсы.

---

## Общие выводы по лабораторной работе

### Достигнутые результаты
1. **Классификация изображений**: Реализованы модели для бинарной и многоклассовой классификации
2. **Transfer Learning**: Сравнены различные предобученные архитектуры
3. **Генеративные модели**: Создана GAN для генерации изображений животных

### Технические навыки
- Работа с PyTorch и свёрточными нейронными сетями
- Применение transfer learning
- Реализация генеративно-состязательных сетей
- Анализ и визуализация результатов

### Рекомендации для дальнейшего развития
- Изучение более современных архитектур (EfficientNet, Vision Transformer)
- Применение продвинутых методов аугментации
- Исследование стабильных GAN архитектур (StyleGAN, BigGAN)